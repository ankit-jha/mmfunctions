{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: confluent_kafka is not installed. Publish to MessageHub not supported.\n",
      "/home/markus/.local/lib/python3.8/site-packages/iotfunctions/bif.py:1877: UserWarning: IoTCalcSettings is deprecated. Use entity type constants instead of a metadata provider to set entity type properties\n",
      "  warnings.warn(('IoTCalcSettings is deprecated. Use entity type constants'\n"
     ]
    }
   ],
   "source": [
    "# Real life data\n",
    "\n",
    "import logging\n",
    "import threading\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import seaborn as seabornInstance\n",
    "from sqlalchemy import Column, Integer, String, Float, DateTime, Boolean, func\n",
    "from iotfunctions import base\n",
    "from iotfunctions import bif\n",
    "from iotfunctions import entity\n",
    "from iotfunctions import metadata\n",
    "from iotfunctions.metadata import EntityType\n",
    "from iotfunctions.db import Database\n",
    "from iotfunctions.enginelog import EngineLogging\n",
    "from iotfunctions import estimator\n",
    "from iotfunctions.ui import (UISingle, UIMultiItem, UIFunctionOutSingle,\n",
    "                 UISingleItem, UIFunctionOutMulti, UIMulti, UIExpression,\n",
    "                 UIText, UIStatusFlag, UIParameters)\n",
    "from mmfunctions.anomaly import (SaliencybasedGeneralizedAnomalyScore, SpectralAnomalyScore,\n",
    "                 FFTbasedGeneralizedAnomalyScore, KMeansAnomalyScore)\n",
    "import datetime as dt\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, r2_score\n",
    "\n",
    "import scipy as sp\n",
    "import scipy.fftpack\n",
    "import skimage as ski\n",
    "\n",
    "from skimage import util as skiutil # for nifty windowing\n",
    "import pyod as pyod\n",
    "from pyod.utils.data import generate_data\n",
    "from pyod.utils.data import evaluate_print\n",
    "from pyod.utils.example import visualize\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.iforest import IForest\n",
    "%matplotlib inline\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "EngineLogging.configure_console_logging(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a 2-layered LSTM in Watson Machine Learning\n",
    "\n",
    " \n",
    "Telemanom ([Detecting Spacecraft Anomalies Using LSTMs and Nonparametric Dynamic Thresholding](https://arxiv.org/pdf/1802.04431.pdf) - 2018\n",
    "\n",
    "\n",
    "Let's find out first what ML libraries are supported by WML.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure to downgrade to sklearn 0.22.2 (no >= 0.23)\n",
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient\n",
    "\n",
    "with open('credentials_wml.json', encoding='utf-8') as F:\n",
    "    wml_credentials = json.loads(F.read())\n",
    "    \n",
    "with open('credentials_cos.json', encoding='utf-8') as F:\n",
    "    cos_credentials = json.loads(F.read())\n",
    "\n",
    "wml_url=wml_credentials['url']\n",
    "wml_instance_id=wml_credentials['instance_id']\n",
    "wml_apikey=wml_credentials['apikey']\n",
    "\n",
    "wml_data_source_type= 's3'\n",
    "\n",
    "\n",
    "# don't use this endpoint\n",
    "cos_endpoint = cos_credentials['endpoints']\n",
    "cos_endpoint = 'https://s3.eu.cloud-object-storage.appdomain.cloud'\n",
    "\n",
    "cos_apikey = cos_credentials['apikey']\n",
    "cos_access_key = cos_credentials['cos_hmac_keys']['access_key_id']\n",
    "cos_secret_key = cos_credentials['cos_hmac_keys']['secret_access_key']\n",
    "# 'https://s3.eu.cloud-object-storage.appdomain.cloud'\n",
    "\n",
    "cos_input_bucket = 'githubanalyzer-donotdelete-pr-b9xa3kxotzh5in'\n",
    "cos_output_bucket = 'githubanalyzer-donotdelete-pr-b9xa3kxotzh5in'\n",
    "\n",
    "client = WatsonMachineLearningAPIClient(wml_credentials)\n",
    "#rep_list = client.runtimes.list(limit=4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First step \n",
    "\n",
    "Apparently Keras is missing out. However, Telemanom is built on Keras, so we have to port it to either Tensorflow, Pytorch, Mxnet, Caffe or Theano.\n",
    "\n",
    "I opted for Pytorch for skill building purposes and ported Telemanom to Pytorch.\n",
    "\n",
    "\n",
    "\n",
    "<small>\n",
    "    \n",
    "```\n",
    "    \n",
    "class LSTM_2L(nn.Module):\n",
    "    def __init__(self, n_features = 1, hidden_dims = [80,80], seq_length = 250,\n",
    "                 batch_size = 64, n_predictions = 10, dropout = 0.3):\n",
    "        super(LSTM_2L, self).__init__()\n",
    "        print ('LSTM_2L', n_features, hidden_dims, seq_length, batch_size, n_predictions, dropout)\n",
    "\n",
    "        self.n_features = n_features\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.seq_length = seq_length\n",
    "        self.num_layers = len(self.hidden_dims)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.lstm1 = nn.LSTM(\n",
    "            input_size = self.n_features,\n",
    "            hidden_size = self.hidden_dims[0],\n",
    "            batch_first = True,\n",
    "            dropout = dropout,\n",
    "            num_layers = 2)\n",
    "\n",
    "        self.linear = nn.Linear(self.hidden_dims[1], n_predictions)\n",
    "        self.init_hidden_state()\n",
    "        \n",
    "    def init_hidden_state(self):\n",
    "\n",
    "        self.hidden = (\n",
    "            torch.randn(self.num_layers, self.batch_size, self.hidden_dims[0]), #.to(self.device),\n",
    "            torch.randn(self.num_layers, self.batch_size, self.hidden_dims[0]), #.to(self.device),\n",
    "            )\n",
    "\n",
    "    def forward(self, sequences):\n",
    "\n",
    "        batch_size, seq_len, n_features = sequences.size()  # batch first\n",
    "\n",
    "        lstm1_out , (h1_n, c1_n) = self.lstm1(sequences, (self.hidden[0], self.hidden[1]))\n",
    "\n",
    "        last_time_step = lstm1_out[:,-1,:]\n",
    "\n",
    "        y_pred = self.linear(last_time_step)\n",
    "\n",
    "        return y_pred\n",
    " ```\n",
    "</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part of mmfunctions\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import telemanom\n",
    "from telemanom.helpers import Config\n",
    "from telemanom.errors import Errors\n",
    "import telemanom.helpers as helpers\n",
    "from telemanom.channel import Channel\n",
    "from telemanom.modeling import Model\n",
    "\n",
    "conf = Config(\"./telemanom/config.yaml\")\n",
    "\n",
    "conf.dictionary['l_s'] = 250\n",
    "conf.dictionary['epochs'] = 80\n",
    "conf.dictionary['dropout'] = 0.2\n",
    "conf.batch_size = 512\n",
    "conf.l_s = 250\n",
    "conf.epochs = 80    # max\n",
    "conf.dropout = 0.2\n",
    "conf.lstm_batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Channel:Channel\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Define structure for local data\n",
    "#              telemanom supports multiple channels to reflect spacecraft sensors, we only need a single one now\n",
    "#\n",
    "device=\"Armstarknew\"\n",
    "chan = Channel(conf, device)\n",
    "helpers.make_dirs(conf.use_id, conf, \"./telemanom\")\n",
    "print(chan)\n",
    "conf\n",
    "\n",
    "# load data\n",
    "\n",
    "chan.train = np.loadtxt('./telemanom/wml_train.csv')\n",
    "chan.test = np.loadtxt('./telemanom/wml_test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following steps replay the code in wml_telemanom.py\n",
    "\n",
    "We jump over the next few cells unless we want to initiate a local training run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-05T15:12:23.639 INFO telemanom.shape_data FFT channel: False\n",
      "(129300, 2)\n",
      "2020-08-05T15:12:24.059 INFO telemanom.shape_data FFT channel: False\n",
      "(129195, 2)\n"
     ]
    }
   ],
   "source": [
    "# producing overlapping windows of length 260 for lookback (250) and prediction (10)\n",
    "chan.shape_data(chan.train, train=True)\n",
    "chan.shape_data(chan.test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_2L 2 [80, 80] 250 64 10 0.2\n",
      "Hidden dimensions are:  2 64 80\n",
      "input shape:  (None, 2)\n"
     ]
    }
   ],
   "source": [
    "# init the Python double stacked LSTM model\n",
    "model = Model(conf, conf.use_id, chan, \"./telemanom\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.model.hidden[0].clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "trainPath = './mytrainedpytorchmodel'\n",
    "\n",
    "try:\n",
    "    model.model.load_state_dict(torch.load(trainPath))\n",
    "    model.model.eval()\n",
    "except Exception:\n",
    "    # drink a coffee - training takes roughly 30 minutes\n",
    "    print('have to train')\n",
    "    model.train_new(chan)\n",
    "    torch.save(model.model.state_dict(), trainPath)\n",
    "\n",
    "#model.train_new(chan)\n",
    "torch.save(model.model.state_dict(), \"./mytrainedpytorchmodel\")\n",
    "\n",
    "# no training run - we've already spent CPU cycles last week\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.6062, -0.1722,  0.1428,  ...,  0.0610,  0.6618, -0.0901],\n",
       "          [ 0.8051,  1.2393, -1.5292,  ...,  1.1181, -1.0100,  0.3673],\n",
       "          [-1.1120,  0.1249,  0.6721,  ..., -1.2269, -0.6833,  0.6239],\n",
       "          ...,\n",
       "          [ 0.7335,  1.2442,  0.9831,  ...,  1.0030, -1.7051,  0.1122],\n",
       "          [-0.6855, -1.0126,  2.3261,  ...,  0.5558,  0.0732,  0.2561],\n",
       "          [ 0.0933,  0.7439,  1.6910,  ..., -0.0913, -0.0059,  1.2361]],\n",
       " \n",
       "         [[ 0.5923, -1.7026,  0.9706,  ...,  0.9155, -1.0606, -1.5867],\n",
       "          [-1.9774,  0.3929, -0.9255,  ...,  1.0483,  0.2315,  0.4416],\n",
       "          [ 1.4346, -0.4047,  0.7843,  ..., -0.8567,  0.2618,  0.1443],\n",
       "          ...,\n",
       "          [-1.3002,  0.1392,  0.0236,  ..., -1.1719,  0.3881, -0.0950],\n",
       "          [-0.6523,  2.1519, -0.6023,  ..., -1.0240, -0.1100, -0.1231],\n",
       "          [-0.7261,  0.4100,  0.2952,  ..., -0.3738,  0.6326, -0.0222]]]),\n",
       " tensor([[[ 0.6062, -0.1722,  0.1428,  ...,  0.0610,  0.6618, -0.0901],\n",
       "          [ 0.8051,  1.2393, -1.5292,  ...,  1.1181, -1.0100,  0.3673],\n",
       "          [-1.1120,  0.1249,  0.6721,  ..., -1.2269, -0.6833,  0.6239],\n",
       "          ...,\n",
       "          [ 0.7335,  1.2442,  0.9831,  ...,  1.0030, -1.7051,  0.1122],\n",
       "          [-0.6855, -1.0126,  2.3261,  ...,  0.5558,  0.0732,  0.2561],\n",
       "          [ 0.0933,  0.7439,  1.6910,  ..., -0.0913, -0.0059,  1.2361]],\n",
       " \n",
       "         [[ 0.5923, -1.7026,  0.9706,  ...,  0.9155, -1.0606, -1.5867],\n",
       "          [-1.9774,  0.3929, -0.9255,  ...,  1.0483,  0.2315,  0.4416],\n",
       "          [ 1.4346, -0.4047,  0.7843,  ..., -0.8567,  0.2618,  0.1443],\n",
       "          ...,\n",
       "          [-1.3002,  0.1392,  0.0236,  ..., -1.1719,  0.3881, -0.0950],\n",
       "          [-0.6523,  2.1519, -0.6023,  ..., -1.0240, -0.1100, -0.1231],\n",
       "          [-0.7261,  0.4100,  0.2952,  ..., -0.3738,  0.6326, -0.0222]]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x, model.model.hidden[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.state_dict of LSTM_2L(\n",
       "  (lstm1): LSTM(2, 80, num_layers=2, batch_first=True, dropout=0.2)\n",
       "  (linear): Linear(in_features=80, out_features=10, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward| Batch size:  64  Sequence length:  80 Output length: 2\n",
      "Shapes  torch.Size([64, 80, 80]) torch.Size([64, 80]) torch.Size([64, 80])\n",
      "forward| Batch size:  tensor(64)  Sequence length:  tensor(80) Output length: tensor(2)\n",
      "Shapes  torch.Size([64, 80, 80]) torch.Size([64, 80]) torch.Size([64, 80])\n",
      "name: \"input.1\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "    shape {\n",
      "      dim {\n",
      "        dim_value: 64\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 80\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 2\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markus/.local/lib/python3.8/site-packages/torch/tensor.py:464: RuntimeWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
      "  warnings.warn('Iterating over a tensor might cause the trace to be incorrect. '\n",
      "/home/markus/.local/lib/python3.8/site-packages/telemanom/modeling.py:93: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  print ('Shapes ', lstm1_out.shape, last_time_step.shape, last_time_step.shape)\n",
      "/home/markus/.local/lib/python3.8/site-packages/torch/onnx/symbolic_opset9.py:1582: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
      "  warnings.warn(\"Exporting a model to ONNX with a batch_size other than 1, \" +\n"
     ]
    }
   ],
   "source": [
    "# attempt to export it as ONNX model\n",
    "\n",
    "# switch off training mode\n",
    "model.model.eval()\n",
    "\n",
    "torch_in = None\n",
    "torch_out = None\n",
    "\n",
    "# switch off autograd, automatic differentiation\n",
    "with torch.no_grad():\n",
    "    \n",
    "    # input tensor\n",
    "    torch_in = torch.randn(64, 80, 2, requires_grad=True)\n",
    "    \n",
    "    # test dimensions\n",
    "    torch_out,_ = model.model(torch_in)\n",
    "\n",
    "    # default export\n",
    "    torch.onnx.export(model.model, torch_in, 'lstm.onnx')\n",
    "    \n",
    "    # test model load\n",
    "    import onnx\n",
    "    onnx_model = onnx.load('lstm.onnx')\n",
    "    # input shape [5, 3, 10]\n",
    "    print(onnx_model.graph.input[0])\n",
    "\n",
    "    onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running onnx models\n",
    "\n",
    "Following the descriptions found here:\n",
    "- https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes  (64, 10) (64, 10)\n",
      "Exported model has been tested with ONNXRuntime, and the result looks good!\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession('lstm.onnx')\n",
    "\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "# compute ONNX Runtime output prediction\n",
    "#   reuse torch_in and torch_out from previous model exporting step\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(torch_in)}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "print ('Shapes ', ort_outs[0].shape, to_numpy(torch_out).shape)\n",
    "\n",
    "# compare ONNX Runtime and PyTorch results\n",
    "np.testing.assert_allclose(to_numpy(torch_out), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
    "\n",
    "\n",
    "print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<strong>Make sure you have uploaded the code in mmfunctions/telemanom as zip file to COS bucket</strong><br/>githubanalyzer-donotdelete-pr-b9xa3kxotzh5in"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "Markdown('<strong>{}</strong><br/>{}'.format('Make sure you have uploaded the code in mmfunctions/telemanom as zip file to COS bucket', cos_input_bucket))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<strong>./telemanom/wml_model.zip\n",
       "found - good</strong><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Zip the code in the ./telemanom subdirectory first\n",
    "\n",
    "import subprocess\n",
    "output = None\n",
    "try:\n",
    "    output = subprocess.check_output(\"ls ./telemanom/wml_model.zip\", shell=True).decode('ascii')  + 'found - good'\n",
    "except Exception:\n",
    "    output = 'Not found - do it now and run \\\"zip -x \\'.git*\\' -9ry wml_model.zip  .\\\" in the telemanom directory'\n",
    "\n",
    "Markdown('<strong>{}</strong><br/>'.format(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          DIR  s3://githubanalyzer-donotdelete-pr-b9xa3kxotzh5in/_wml_checkpoints/\r\n",
      "                          DIR  s3://githubanalyzer-donotdelete-pr-b9xa3kxotzh5in/b6c198e3-35b1-4ae3-85db-b542ea460ed2/\r\n",
      "                          DIR  s3://githubanalyzer-donotdelete-pr-b9xa3kxotzh5in/d7498a25-3455-468a-bb11-e54bdeec346d/\r\n",
      "                          DIR  s3://githubanalyzer-donotdelete-pr-b9xa3kxotzh5in/notebook/\r\n",
      "                          DIR  s3://githubanalyzer-donotdelete-pr-b9xa3kxotzh5in/training-YAYfZiIGR/\r\n",
      "                          DIR  s3://githubanalyzer-donotdelete-pr-b9xa3kxotzh5in/training-nFSMWiIMg/\r\n",
      "2020-08-05 13:12      3563355  s3://githubanalyzer-donotdelete-pr-b9xa3kxotzh5in/wml_model.zip\r\n"
     ]
    }
   ],
   "source": [
    "# check whether we have uploaded the code\n",
    "!s3cmd --access_key {cos_access_key} --secret_key {cos_secret_key} \\\n",
    "--access_token {cos_apikey} --host s3.eu.cloud-object-storage.appdomain.cloud --host-bucket=s3.eu.cloud-object-storage.appdomain.cloud \\\n",
    "ls s3://githubanalyzer-donotdelete-pr-b9xa3kxotzh5in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now starting to work with WML\n",
    "#\n",
    "#   make sure we go with Open Neural Network Exchange (ONNX) to allow for pytorch model exporting\n",
    "# \n",
    "\n",
    "wml_train_code='./telemanom/wml_model.zip' # where this notebook finds the code\n",
    "\n",
    "wml_execution_command='python3 wml_telemanom.py' # command to start training\n",
    "\n",
    "wml_framework_name='pytorch-onnx'\n",
    "\n",
    "# we have to run on pytorch-onnx 1.2 (Open Neural Network Exchange) but it's not yet available\n",
    "wml_framework_version='1.1'   # go with 1.1 until GA of CloudPak for Data 3.5 \n",
    "wml_runtime = 'python'\n",
    "wml_runtime_version='3.6' # and python 3.6\n",
    "\n",
    "wml_run_definition = 'wml-pytorch-definition' # dummy name\n",
    "wml_run_name = 'wml-pytorch-run' # more dummy\n",
    "wml_model_name='wml-tensorflow-miregal' # even more dummy\n",
    "\n",
    "wml_compute_name='k80'  # free tier machine type\n",
    "wml_compute_nodes='1'   # free tier\n",
    "\n",
    "wml_runtime_version_v4 = wml_framework_version + '-py' + wml_runtime_version   # sdk level\n",
    "wml_compute_nodes_v4 = int(wml_compute_nodes)\n",
    "\n",
    "model_code = wml_train_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./telemanom/wml_model.zip'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wml_train_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#   (custom) libraries serve as meta data for model code to be installed on top of predefined container images\n",
    "#\n",
    "# define library meta data for our training code\n",
    "#\n",
    "lib_meta = {\n",
    "    client.runtimes.LibraryMetaNames.NAME: wml_run_definition,\n",
    "    client.runtimes.LibraryMetaNames.VERSION: wml_framework_version,\n",
    "    client.runtimes.LibraryMetaNames.FILEPATH: model_code,\n",
    "    client.runtimes.LibraryMetaNames.PLATFORM: {\"name\": wml_framework_name, \"versions\": [wml_framework_version]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delete  {'metadata': {'guid': '99dd3825-2a0a-4a35-b271-b40e27fc7a44', 'id': '99dd3825-2a0a-4a35-b271-b40e27fc7a44', 'modified_at': '2020-08-05T13:13:05.420Z', 'created_at': '2020-08-05T13:12:48.603Z', 'href': '/v4/libraries/99dd3825-2a0a-4a35-b271-b40e27fc7a44'}, 'entity': {'space': {'id': '88740b60-6b2f-4f74-b6d8-20528d14db8b', 'href': '/v4/spaces/88740b60-6b2f-4f74-b6d8-20528d14db8b'}, 'name': 'wml-pytorch-definition', 'version': '1.1', 'platform': {'name': 'pytorch-onnx', 'versions': ['1.1']}}}\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# do we have a library with that name defined ?\n",
    "#   delete it first and then store the new updated library\n",
    "#\n",
    "library_details = client.runtimes.get_library_details()\n",
    "for library_detail in library_details['resources']:\n",
    "    if library_detail['entity']['name'] == wml_run_definition:\n",
    "        # Delete library if exist because we cannot update model_code\n",
    "        uid = client.runtimes.get_library_uid(library_detail)\n",
    "        print ('delete ', library_detail)\n",
    "        client.repository.delete(uid)\n",
    "        break\n",
    "\n",
    "custom_library_details = client.runtimes.store_library(lib_meta)\n",
    "custom_library_uid = client.runtimes.get_library_uid(custom_library_details)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#  Pipelines define a sequence of operations\n",
    "#\n",
    "# define a pipeline with a single entry (node) for the training run\n",
    "#  we could add more node for scaling/normalizing, imputation, feature extraction, \"you name it\"\n",
    "#\n",
    "doc = {\n",
    "    \"doc_type\": \"pipeline\",\n",
    "    \"version\": \"2.0\",\n",
    "    \"primary_pipeline\": wml_framework_name,\n",
    "    \"pipelines\": [{\n",
    "        \"id\": wml_framework_name,\n",
    "        \"runtime_ref\": \"hybrid\",\n",
    "        \"nodes\": [{\n",
    "            \"id\": \"training\",\n",
    "            \"type\": \"model_node\",\n",
    "            \"op\": \"dl_train\",\n",
    "            \"runtime_ref\": wml_run_name,\n",
    "            \"inputs\": [],\n",
    "            \"outputs\": [],\n",
    "            \"parameters\": {\n",
    "                \"name\": \"pytorch-telemanom\",\n",
    "                \"description\": wml_run_definition,\n",
    "                \"command\": wml_execution_command,\n",
    "                \"training_lib_href\": \"/v4/libraries/\"+custom_library_uid,\n",
    "                \"compute\": {\n",
    "                    \"name\": wml_compute_name,            # specify where to run it (not that I have a choice)\n",
    "                    \"nodes\": wml_compute_nodes_v4\n",
    "                }\n",
    "            }\n",
    "        }]\n",
    "    }],\n",
    "    \"runtimes\": [{\n",
    "        \"id\": wml_run_name,\n",
    "        \"name\": wml_framework_name,         # run it on a pytorch image\n",
    "        \"version\": wml_runtime_version_v4\n",
    "    }]\n",
    "}\n",
    "\n",
    "# put it in metadata object\n",
    "metadata = {\n",
    "    client.repository.PipelineMetaNames.NAME: wml_run_name,\n",
    "    client.repository.PipelineMetaNames.DOCUMENT: doc\n",
    "}\n",
    "\n",
    "# and create the pipeline\n",
    "pipeline_id = client.pipelines.get_uid(client.repository.store_pipeline(meta_props=metadata))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metadata': {'name': 'wml-pytorch-run',\n",
       "  'guid': 'fb11e3a0-b123-4551-9225-28ff94146536',\n",
       "  'rev': '503e3bb5-8d87-43e4-9b13-8265b09fa190',\n",
       "  'id': 'fb11e3a0-b123-4551-9225-28ff94146536',\n",
       "  'modified_at': '2020-08-05T17:37:16.224Z',\n",
       "  'created_at': '2020-08-05T17:37:16.159Z',\n",
       "  'href': '/v4/pipelines/fb11e3a0-b123-4551-9225-28ff94146536?rev=503e3bb5-8d87-43e4-9b13-8265b09fa190'},\n",
       " 'entity': {'space': {'id': '88740b60-6b2f-4f74-b6d8-20528d14db8b',\n",
       "   'href': '/v4/spaces/88740b60-6b2f-4f74-b6d8-20528d14db8b'},\n",
       "  'name': 'wml-pytorch-run',\n",
       "  'document': {'doc_type': 'pipeline',\n",
       "   'version': '2.0',\n",
       "   'pipelines': [{'id': 'pytorch-onnx',\n",
       "     'runtime_ref': 'hybrid',\n",
       "     'nodes': [{'outputs': [],\n",
       "       'id': 'training',\n",
       "       'inputs': [],\n",
       "       'type': 'model_node',\n",
       "       'parameters': {'name': 'pytorch-telemanom',\n",
       "        'description': 'wml-pytorch-definition',\n",
       "        'compute': {'name': 'k80', 'nodes': 1},\n",
       "        'command': 'python3 wml_telemanom.py',\n",
       "        'training_lib_href': '/v4/libraries/017d6899-e8eb-4b89-a409-b843f741afe0'},\n",
       "       'runtime_ref': 'wml-pytorch-run',\n",
       "       'op': 'dl_train'}]}],\n",
       "   'runtimes': [{'id': 'wml-pytorch-run',\n",
       "     'name': 'pytorch-onnx',\n",
       "     'version': '1.2-py3.6'}],\n",
       "   'primary_pipeline': 'pytorch-onnx'}}}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is my pipeline now\n",
    "client.pipelines.get_details(pipeline_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-05T19:37:18.138 WARNING watson_machine_learning_client.wml_client_error.__init__ Failure during training. (POST https://eu-de.ml.cloud.ibm.com/v4/trainings)\n",
      "Status code: 400, body: {\n",
      "  \"trace\": \"774c7e4e470ee9465a943e8c92d97d47\",\n",
      "  \"errors\": [{\n",
      "    \"code\": \"bad_request\",\n",
      "    \"message\": \"Unsupported training runtime pytorch-onnx_1.2-py3.6\"\n",
      "  }]\n",
      "}\n"
     ]
    },
    {
     "ename": "ApiRequestFailure",
     "evalue": "Failure during training. (POST https://eu-de.ml.cloud.ibm.com/v4/trainings)\nStatus code: 400, body: {\n  \"trace\": \"774c7e4e470ee9465a943e8c92d97d47\",\n  \"errors\": [{\n    \"code\": \"bad_request\",\n    \"message\": \"Unsupported training runtime pytorch-onnx_1.2-py3.6\"\n  }]\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mApiRequestFailure\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-3d51210104ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m }\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mtraining_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_uid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_props\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_details\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get status\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/watson_machine_learning_client/training.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, meta_props, asynchronous)\u001b[0m\n\u001b[1;32m    395\u001b[0m                                                     headers=self._client._get_headers(), verify=False)\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         \u001b[0mrun_details\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m201\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu'training'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_train_post\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0mtrained_model_guid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_uid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_details\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/watson_machine_learning_client/wml_resource.py\u001b[0m in \u001b[0;36m_handle_response\u001b[0;34m(self, expected_status_code, operationName, response, json_response)\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mApiRequestFailure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'Failure during {}.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperationName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mApiRequestFailure\u001b[0m: Failure during training. (POST https://eu-de.ml.cloud.ibm.com/v4/trainings)\nStatus code: 400, body: {\n  \"trace\": \"774c7e4e470ee9465a943e8c92d97d47\",\n  \"errors\": [{\n    \"code\": \"bad_request\",\n    \"message\": \"Unsupported training runtime pytorch-onnx_1.2-py3.6\"\n  }]\n}"
     ]
    }
   ],
   "source": [
    "# \n",
    "# finally start the training run for v4\n",
    "#   tell it where to load data and model code from and dump results to\n",
    "#\n",
    "metadata = {\n",
    "    client.training.ConfigurationMetaNames.TRAINING_RESULTS_REFERENCE: {\n",
    "        \"name\": \"training-results-reference_name\",\n",
    "        \"connection\": {\n",
    "            \"endpoint_url\": cos_endpoint,\n",
    "            \"access_key_id\": cos_access_key,\n",
    "            \"secret_access_key\": cos_secret_key\n",
    "        },\n",
    "        \"location\": {\n",
    "            \"bucket\": cos_output_bucket\n",
    "        },\n",
    "        \"type\": wml_data_source_type\n",
    "    },\n",
    "    client.training.ConfigurationMetaNames.TRAINING_DATA_REFERENCES:[{\n",
    "        \"name\": \"training_input_data\",\n",
    "        \"type\": wml_data_source_type,\n",
    "        \"connection\": {\n",
    "            \"endpoint_url\": cos_endpoint,\n",
    "            \"access_key_id\": cos_access_key,\n",
    "            \"secret_access_key\": cos_secret_key\n",
    "        },\n",
    "        \"location\": {\n",
    "            \"bucket\": cos_input_bucket\n",
    "        }\n",
    "    }],\n",
    "    client.training.ConfigurationMetaNames.PIPELINE_UID: pipeline_id\n",
    "}\n",
    "\n",
    "training_id = client.training.get_uid(client.training.run(meta_props=metadata))\n",
    "print(\"training_id\", client.training.get_details(training_id))\n",
    "print(\"get status\", client.training.get_status(training_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_details = client.training.get_details(training_id)\n",
    "run_uid = training_id\n",
    "\n",
    "# print logs\n",
    "\n",
    "client.training.monitor_logs(run_uid)\n",
    "client.training.monitor_metrics(run_uid)\n",
    "\n",
    "# should not have run after restarting the notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': {'text': 'Node training: Shapes  torch.Size([64, 250, 80]) torch.Size([64, 80]) torch.Size([64, 80])\\n',\n",
       "  'level': 'info'},\n",
       " 'running_at': '2020-08-05T13:14:37.894Z',\n",
       " 'state': 'running'}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run_uid='2c002ed8-e508-4f20-bb15-b789f39a6974'\n",
    "status = client.training.get_status(run_uid)\n",
    "status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#client.training.cancel(run_uid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### if training seems to have failed, just look at the logs in our COS output bucket\n",
    "\n",
    "Dumb me, in the previous run I forgot to import sys.\n",
    "\n",
    "Fortunately model training has succeeded and the model has been stored in COS. Phew.\n",
    "\n",
    "<small>\n",
    "\n",
    "```\n",
    "...\n",
    "Batch  1611\n",
    "Batch  1612\n",
    "After batch  1612 0.002384878075476655\n",
    "[1] Training loss: 0.002384878075476655 \t Validation loss: 0.0014487287297119242 \n",
    "Training complete...\n",
    "Model saved in file: /mnt/results/githubanalyzer-donotdelete-pr-b9xa3kxotzh5in/training-h9VOfZVMR/model\n",
    "['_submitted_code', 'learner-1', 'model', 'training-log.txt']\n",
    "/mnt/results/githubanalyzer-donotdelete-pr-b9xa3kxotzh5in/training-h9VOfZVMR\n",
    "Traceback (most recent call last):\n",
    "  File \"wml_telemanom.py\", line 61, in <module>\n",
    "    sys.stdout.flush()\n",
    "NameError: name 'sys' is not defined\n",
    "```\n",
    "    \n",
    "</small>\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1-py3.6'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wml_runtime_version_v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's store the model\n",
    "\n",
    "meta_props_pyt = {\n",
    "    client.repository.ModelMetaNames.NAME: wml_model_name,\n",
    "    client.repository.ModelMetaNames.RUNTIME_UID: wml_framework_name + '_' + wml_runtime_version_v4,\n",
    "    client.repository.ModelMetaNames.TYPE: wml_framework_name + '_' + wml_framework_version\n",
    "}\n",
    "\n",
    "model_details = client.repository.store_model(run_uid, meta_props=meta_props_pyt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metadata': {'name': 'wml-tensorflow-miregal',\n",
       "  'guid': 'eeac7d0a-69e7-4f81-ac5b-35eff542a841',\n",
       "  'rev': 'cea0af8b-0ebf-4e0e-88d9-69b98c78eefe',\n",
       "  'id': 'eeac7d0a-69e7-4f81-ac5b-35eff542a841',\n",
       "  'modified_at': '2020-07-27T14:55:59.286Z',\n",
       "  'created_at': '2020-07-27T14:55:59.219Z',\n",
       "  'href': '/v4/models/eeac7d0a-69e7-4f81-ac5b-35eff542a841?rev=cea0af8b-0ebf-4e0e-88d9-69b98c78eefe'},\n",
       " 'entity': {'name': 'wml-tensorflow-miregal',\n",
       "  'content_status': {'state': 'persisting'},\n",
       "  'import': {'location': {'training': '3dd32ad4-d6bf-45be-b09f-cf2b79e75e7b',\n",
       "    'pipeline_model': '3dd32ad4-d6bf-45be-b09f-cf2b79e75e7b/pipeline-model.json',\n",
       "    'training_status': '3dd32ad4-d6bf-45be-b09f-cf2b79e75e7b/training-status.json',\n",
       "    'pipeline': '3dd32ad4-d6bf-45be-b09f-cf2b79e75e7b/pipeline.json',\n",
       "    'bucket': 'githubanalyzer-donotdelete-pr-b9xa3kxotzh5in',\n",
       "    'assets_path': '3dd32ad4-d6bf-45be-b09f-cf2b79e75e7b/assets'},\n",
       "   'type': 's3',\n",
       "   'connection': {'access_key_id': 'cc04444c99374c9e9589b8f85e931323',\n",
       "    'secret_access_key': '1a5062d937b09507a05b521a41b8baf6848c0cd6936e2864',\n",
       "    'endpoint_url': 'https://control.cloud-object-storage.cloud.ibm.com/v2/endpoints'}},\n",
       "  'space': {'id': '88740b60-6b2f-4f74-b6d8-20528d14db8b',\n",
       "   'href': '/v4/spaces/88740b60-6b2f-4f74-b6d8-20528d14db8b'},\n",
       "  'type': 'pytorch_1.1',\n",
       "  'runtime': {'id': 'pytorch_1.1-py3.6',\n",
       "   'href': '/v4/runtimes/pytorch_1.1-py3.6'}}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"trace\":\"-sulpksdfbwj8\",\"errors\":[{\"code\":\"unsupported_framework_details\",\"message\":\"Models of framework pytorch are not supported.\"}]}\n",
      "\n",
      "\n",
      "--------------------------\n",
      "Deployment creation failed\n",
      "--------------------------\n",
      "\n",
      "\n",
      "2020-07-27T17:00:12.499 WARNING watson_machine_learning_client.wml_client_error.__init__ Deployment creation failed. Error: 400. {\"trace\":\"-sulpksdfbwj8\",\"errors\":[{\"code\":\"unsupported_framework_details\",\"message\":\"Models of framework pytorch are not supported.\"}]}\n"
     ]
    },
    {
     "ename": "WMLClientError",
     "evalue": "Deployment creation failed. Error: 400. {\"trace\":\"-sulpksdfbwj8\",\"errors\":[{\"code\":\"unsupported_framework_details\",\"message\":\"Models of framework pytorch are not supported.\"}]}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWMLClientError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-3e5ef74ce1e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeployments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfigurationMetaNames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mONLINE\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     }\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdeployment_details\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeployments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_details\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metadata'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_props\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mdeployment_details\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/watson_machine_learning_client/deployments.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, artifact_uid, meta_props, rev_id, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                 \u001b[0mprint_text_header_h2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mWMLClientError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. Error: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mreason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;31m#return self._handle_response(202, u'created deployment', response)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWMLClientError\u001b[0m: Deployment creation failed. Error: 400. {\"trace\":\"-sulpksdfbwj8\",\"errors\":[{\"code\":\"unsupported_framework_details\",\"message\":\"Models of framework pytorch are not supported.\"}]}"
     ]
    }
   ],
   "source": [
    "#\n",
    "# finally let's deploy it\n",
    "#   use model name as deployment name\n",
    "#\n",
    "meta_props = {\n",
    "        client.deployments.ConfigurationMetaNames.NAME: wml_model_name,\n",
    "        client.deployments.ConfigurationMetaNames.ONLINE: {}\n",
    "    }\n",
    "deployment_details = client.deployments.create(model_details['metadata']['id'], meta_props)\n",
    "deployment_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-27T16:57:28.619 WARNING watson_machine_learning_client.wml_client_error.__init__ Unexpected type of 'model_uid', expected: '<class 'str'>', actual: '<class 'dict'>'.\n"
     ]
    },
    {
     "ename": "UnexpectedType",
     "evalue": "Unexpected type of 'model_uid', expected: '<class 'str'>', actual: '<class 'dict'>'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedType\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-3a037dc416c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_uid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_details\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_details\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepository\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_details\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_uid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/watson_machine_learning_client/repository.py\u001b[0m in \u001b[0;36mget_model_details\u001b[0;34m(self, model_uid, limit)\u001b[0m\n\u001b[1;32m   1040\u001b[0m         \"\"\"\n\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_details\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_uid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdocstring_parameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'str_type'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSTR_TYPE_NAME\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/watson_machine_learning_client/models.py\u001b[0m in \u001b[0;36mget_details\u001b[0;34m(self, model_uid, limit)\u001b[0m\n\u001b[1;32m   1462\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_if_either_is_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m         \u001b[0mmodel_uid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr_type_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_uid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1464\u001b[0;31m         \u001b[0mModels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_uid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu'model_uid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTR_TYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1465\u001b[0m         \u001b[0mModels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu'limit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/watson_machine_learning_client/wml_resource.py\u001b[0m in \u001b[0;36m_validate_type\u001b[0;34m(el, el_name, expected_type, mandatory)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mUnexpectedType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedType\u001b[0m: Unexpected type of 'model_uid', expected: '<class 'str'>', actual: '<class 'dict'>'."
     ]
    }
   ],
   "source": [
    "model_uid = model_details\n",
    "model_details = client.repository.get_model_details(model_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WTF ?\n",
    "```\n",
    "Training a PyTorch model using the Watson Machine Learning training service is supported, but deploying a trained PyTorch model in your Watson Machine Learning service is not supported.\n",
    "```\n",
    "https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/pm_service_supported_frameworks.html\n",
    "\n",
    "it took me by surprise: \n",
    "\n",
    "* WML doesn't support training Keras models in the cloud, but you can upload the h5 model and treat it as a tensorflow model\n",
    "\n",
    "Fortunately there is the wml_dev slack channel as last resort ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training parameters\n",
    "\n",
    "```\n",
    "loss_metric: 'mse'    # minimize mean square error\n",
    "optimizer: 'adam'     # sort of adaptive stochastic gradient descent\n",
    "validation_split: 0.2 # 20% of the data is used for validating (val_loss)\n",
    "dropout: 0.3          # ditch 30% of the LSTMs results when minimizing the loss function to avoid overfitting\n",
    "lstm_batch_size: 64   # number of training data batches to evaluate per optimizer run to update the model’s parameters\n",
    "\n",
    "patience: 10          # try at least 10 times to decrease val_loss smaller by ...\n",
    "min_delta: 0.0003     # ... at least min_delta, else stop, so we get at least 'patience' epochs\n",
    "epochs: 35            # no more than 35 passes through the entier training dataset.\n",
    "\n",
    "l_s: 250              # lookback: num previous timesteps provided to model to predict future values\n",
    "n_predictions: 10     # number of steps ahead to predict\n",
    "```\n",
    "\n",
    "This is defined in `telemanom/config.yaml`\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

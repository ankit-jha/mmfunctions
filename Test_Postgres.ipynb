{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markus/.local/lib/python3.7/site-packages/iotfunctions/bif.py:1899: UserWarning: IoTCalcSettings is deprecated. Use entity type constants instead of a metadata provider to set entity type properties\n",
      "  warnings.warn(('IoTCalcSettings is deprecated. Use entity type constants'\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import threading\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as seabornInstance\n",
    "from sqlalchemy import Column, Integer, String, Float, DateTime, Boolean, func\n",
    "from iotfunctions import base\n",
    "from iotfunctions import bif\n",
    "from iotfunctions import entity\n",
    "from iotfunctions import metadata\n",
    "from iotfunctions.metadata import EntityType\n",
    "from iotfunctions.db import Database\n",
    "from iotfunctions.enginelog import EngineLogging\n",
    "from iotfunctions import estimator\n",
    "from iotfunctions.ui import (UISingle, UIMultiItem, UIFunctionOutSingle,\n",
    "                 UISingleItem, UIFunctionOutMulti, UIMulti, UIExpression,\n",
    "                 UIText, UIStatusFlag, UIParameters)\n",
    "from iotfunctions.enginelog import EngineLogging\n",
    "from iotfunctions import pipeline as pp\n",
    "from iotfunctions.pipeline import SqlAlchemyDataWriter, JobController, DataWriterFile, DataAggregator\n",
    "\n",
    "import datetime as dt\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-01T20:37:11.501 DEBUG iotfunctions.enginelog.configure_console_logging Console logging has been configured. Level = 10\n"
     ]
    }
   ],
   "source": [
    "credentials = {\n",
    "  \"tenantId\": \"AnalyticsServiceDev\",\n",
    "  \"as_api_host\": \"https://api-dev.connectedproducts.internetofthings.ibmcloud.com\",\n",
    "  \"as_api_key\": \"a-69xgm4-8bdgtvnsv4\",\n",
    "  \"as_api_token\": \"9X_tMKdupOiJ!mzaPV\",\n",
    "  \"config\" : {\n",
    "      \"objectStorageEndpoint\" : \"https://s3-api.us-geo.objectstorage.softlayer.net\",\n",
    "      \"bos_runtime_bucket\" : \"analytics-runtime-analyticsservicedev-799d2008b460\",\n",
    "      \"bos_logs_bucket\" : \"analytics-logs-analyticsservicedev-32703c52ec8b\"\n",
    "  },\n",
    "  \"objectStorage\": {\n",
    "      \"username\" : \"58ddd86b5de8468b819d385046f17033\",\n",
    "      \"password\" : \"ee0d6c5521ce9ff100f91b0e37d4eb8cc1a038b5a6d05b38\",\n",
    "      \"region\" : \"us\",\n",
    "      \"endpoint\" : \"https://s3-api.us-geo.objectstorage.softlayer.net\"\n",
    "  },\n",
    "  \"db2-nada\": {\n",
    "    \"username\": \"bluadmin\",\n",
    "    \"password\": \"ZmM5MmE5NmZkZGZl\",\n",
    "    \"databaseName\": \"BLUDB\",\n",
    "    \"port\": 50000,\n",
    "    \"httpsUrl\": \"https://dashdb-enterprise-yp-dal13-74.services.dal.bluemix.net:50000\",\n",
    "    \"host\": \"dashdb-enterprise-yp-dal13-74.services.dal.bluemix.net\"\n",
    "  },\n",
    "  \"postgresql\": {\n",
    "      \"username\": \"ibm_cloud_7d201f19_ffd0_475b_b058_26a76cec9905\",\n",
    "      \"password\": \"04cdf453585baa96c19b5e7f65c7e2762288c3c2a6043ac059283fe38a3761f1\",\n",
    "      \"region\": \"us\",\n",
    "      \"host\": \"0e899846-39a1-4b58-9b60-67cb5a0aada4.bkvfvtld0lmh0umkfi70.databases.appdomain.cloud\",\n",
    "      \"port\": 32698,\n",
    "      \"databaseName\": \"ibmclouddb\"\n",
    "  }\n",
    "}\n",
    "EngineLogging.configure_console_logging(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-01T20:37:12.451 DEBUG iotfunctions.db.__init__ Unable to locate message_hub credentials. Database object created, but it will not be able interact with message hub.\n",
      "2019-10-01T20:37:12.451 INFO iotfunctions.db.__init__ Connection string for SqlAlchemy => postgresql): postgresql://ibm_cloud_7d201f19_ffd0_475b_b058_26a76cec9905:04cdf453585baa96c19b5e7f65c7e2762288c3c2a6043ac059283fe38a3761f1@0e899846-39a1-4b58-9b60-67cb5a0aada4.bkvfvtld0lmh0umkfi70.databases.appdomain.cloud:32698/ibmclouddb\n",
      "2019-10-01T20:37:12.452 DEBUG iotfunctions.db.__init__ created a CosClient object\n",
      "2019-10-01T20:37:12.472 DEBUG iotfunctions.db.__init__ Db connection established\n",
      "2019-10-01T20:37:12.473 DEBUG urllib3.connectionpool._new_conn Starting new HTTPS connection (1): api-dev.connectedproducts.internetofthings.ibmcloud.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markus/.local/lib/python3.7/site-packages/urllib3/connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-01T20:37:18.234 DEBUG urllib3.connectionpool._make_request https://api-dev.connectedproducts.internetofthings.ibmcloud.com:443 \"GET /api/meta/v1/AnalyticsServiceDev/entityType HTTP/1.1\" 200 None\n",
      "2019-10-01T20:37:18.812 DEBUG iotfunctions.db.http_request http request successful. status 200\n",
      "<iotfunctions.db.Database object at 0x7fb53c4ea978>\n"
     ]
    }
   ],
   "source": [
    "db_schema = None\n",
    "db = Database(credentials=credentials)\n",
    "print (db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MetaData(bind=Engine(postgresql://ibm_cloud_7d201f19_ffd0_475b_b058_26a76cec9905:***@0e899846-39a1-4b58-9b60-67cb5a0aada4.bkvfvtld0lmh0umkfi70.databases.appdomain.cloud:32698/ibmclouddb))\n"
     ]
    }
   ],
   "source": [
    "print (db.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IOT_TYPE_7EQAJ\n"
     ]
    }
   ],
   "source": [
    "table = db.get_table(\"IOT_TYPE_7EQAJ\")\n",
    "start_ts = dt.datetime.utcnow() - dt.timedelta(days=40)\n",
    "end_ts = dt.datetime.utcnow()\n",
    "df = db.read_table(table, None, None, None, \"rcv_timestamp_utc\", start_ts, end_ts)\n",
    "print (table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>field1</th>\n",
       "      <th>field3</th>\n",
       "      <th>field2</th>\n",
       "      <th>devicetype</th>\n",
       "      <th>deviceid</th>\n",
       "      <th>logicalinterface_id</th>\n",
       "      <th>eventtype</th>\n",
       "      <th>format</th>\n",
       "      <th>rcv_timestamp_utc</th>\n",
       "      <th>updated_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>True</td>\n",
       "      <td>field2 description</td>\n",
       "      <td>TYPE_7EQAJ</td>\n",
       "      <td>DEVICE_7EQAJ</td>\n",
       "      <td>5d82799ce24d7e0022912865</td>\n",
       "      <td>tree</td>\n",
       "      <td>json</td>\n",
       "      <td>2019-09-18 18:38:36.875</td>\n",
       "      <td>2019-09-18 18:38:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>172.0</td>\n",
       "      <td>False</td>\n",
       "      <td>field2 description</td>\n",
       "      <td>TYPE_7EQAJ</td>\n",
       "      <td>DEVICE_7EQAJ</td>\n",
       "      <td>5d82799ce24d7e0022912865</td>\n",
       "      <td>tree</td>\n",
       "      <td>json</td>\n",
       "      <td>2019-09-18 18:38:37.614</td>\n",
       "      <td>2019-09-18 18:38:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>771.0</td>\n",
       "      <td>False</td>\n",
       "      <td>field2 description</td>\n",
       "      <td>TYPE_7EQAJ</td>\n",
       "      <td>DEVICE_7EQAJ</td>\n",
       "      <td>5d82799ce24d7e0022912865</td>\n",
       "      <td>tree</td>\n",
       "      <td>json</td>\n",
       "      <td>2019-09-18 18:38:39.745</td>\n",
       "      <td>2019-09-18 18:38:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>940.0</td>\n",
       "      <td>True</td>\n",
       "      <td>field2 description</td>\n",
       "      <td>TYPE_7EQAJ</td>\n",
       "      <td>DEVICE_7EQAJ</td>\n",
       "      <td>5d82799ce24d7e0022912865</td>\n",
       "      <td>tree</td>\n",
       "      <td>json</td>\n",
       "      <td>2019-09-18 18:38:38.355</td>\n",
       "      <td>2019-09-18 18:38:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>910.0</td>\n",
       "      <td>True</td>\n",
       "      <td>field2 description</td>\n",
       "      <td>TYPE_7EQAJ</td>\n",
       "      <td>DEVICE_7EQAJ</td>\n",
       "      <td>5d82799ce24d7e0022912865</td>\n",
       "      <td>tree</td>\n",
       "      <td>json</td>\n",
       "      <td>2019-09-18 18:38:38.989</td>\n",
       "      <td>2019-09-18 18:38:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>580.0</td>\n",
       "      <td>True</td>\n",
       "      <td>field2 description</td>\n",
       "      <td>TYPE_7EQAJ</td>\n",
       "      <td>DEVICE_7EQAJ</td>\n",
       "      <td>5d82799ce24d7e0022912865</td>\n",
       "      <td>tree</td>\n",
       "      <td>json</td>\n",
       "      <td>2019-09-18 18:38:40.695</td>\n",
       "      <td>2019-09-18 18:38:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>710.0</td>\n",
       "      <td>False</td>\n",
       "      <td>field2 description</td>\n",
       "      <td>TYPE_7EQAJ</td>\n",
       "      <td>DEVICE_7EQAJ</td>\n",
       "      <td>5d82799ce24d7e0022912865</td>\n",
       "      <td>tree</td>\n",
       "      <td>json</td>\n",
       "      <td>2019-09-18 18:38:41.355</td>\n",
       "      <td>2019-09-18 18:38:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>240.0</td>\n",
       "      <td>False</td>\n",
       "      <td>field2 description</td>\n",
       "      <td>TYPE_7EQAJ</td>\n",
       "      <td>DEVICE_7EQAJ</td>\n",
       "      <td>5d82799ce24d7e0022912865</td>\n",
       "      <td>tree</td>\n",
       "      <td>json</td>\n",
       "      <td>2019-09-18 18:38:42.001</td>\n",
       "      <td>2019-09-18 18:38:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>921.0</td>\n",
       "      <td>False</td>\n",
       "      <td>field2 description</td>\n",
       "      <td>TYPE_7EQAJ</td>\n",
       "      <td>DEVICE_7EQAJ</td>\n",
       "      <td>5d82799ce24d7e0022912865</td>\n",
       "      <td>tree</td>\n",
       "      <td>json</td>\n",
       "      <td>2019-09-18 18:38:42.706</td>\n",
       "      <td>2019-09-18 18:38:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>319.0</td>\n",
       "      <td>False</td>\n",
       "      <td>field2 description</td>\n",
       "      <td>TYPE_7EQAJ</td>\n",
       "      <td>DEVICE_7EQAJ</td>\n",
       "      <td>5d82799ce24d7e0022912865</td>\n",
       "      <td>tree</td>\n",
       "      <td>json</td>\n",
       "      <td>2019-09-18 18:38:43.468</td>\n",
       "      <td>2019-09-18 18:38:43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   field1  field3              field2  devicetype      deviceid  \\\n",
       "0   540.0    True  field2 description  TYPE_7EQAJ  DEVICE_7EQAJ   \n",
       "1   172.0   False  field2 description  TYPE_7EQAJ  DEVICE_7EQAJ   \n",
       "2   771.0   False  field2 description  TYPE_7EQAJ  DEVICE_7EQAJ   \n",
       "3   940.0    True  field2 description  TYPE_7EQAJ  DEVICE_7EQAJ   \n",
       "4   910.0    True  field2 description  TYPE_7EQAJ  DEVICE_7EQAJ   \n",
       "5   580.0    True  field2 description  TYPE_7EQAJ  DEVICE_7EQAJ   \n",
       "6   710.0   False  field2 description  TYPE_7EQAJ  DEVICE_7EQAJ   \n",
       "7   240.0   False  field2 description  TYPE_7EQAJ  DEVICE_7EQAJ   \n",
       "8   921.0   False  field2 description  TYPE_7EQAJ  DEVICE_7EQAJ   \n",
       "9   319.0   False  field2 description  TYPE_7EQAJ  DEVICE_7EQAJ   \n",
       "\n",
       "        logicalinterface_id eventtype format       rcv_timestamp_utc  \\\n",
       "0  5d82799ce24d7e0022912865      tree   json 2019-09-18 18:38:36.875   \n",
       "1  5d82799ce24d7e0022912865      tree   json 2019-09-18 18:38:37.614   \n",
       "2  5d82799ce24d7e0022912865      tree   json 2019-09-18 18:38:39.745   \n",
       "3  5d82799ce24d7e0022912865      tree   json 2019-09-18 18:38:38.355   \n",
       "4  5d82799ce24d7e0022912865      tree   json 2019-09-18 18:38:38.989   \n",
       "5  5d82799ce24d7e0022912865      tree   json 2019-09-18 18:38:40.695   \n",
       "6  5d82799ce24d7e0022912865      tree   json 2019-09-18 18:38:41.355   \n",
       "7  5d82799ce24d7e0022912865      tree   json 2019-09-18 18:38:42.001   \n",
       "8  5d82799ce24d7e0022912865      tree   json 2019-09-18 18:38:42.706   \n",
       "9  5d82799ce24d7e0022912865      tree   json 2019-09-18 18:38:43.468   \n",
       "\n",
       "          updated_utc  \n",
       "0 2019-09-18 18:38:36  \n",
       "1 2019-09-18 18:38:37  \n",
       "2 2019-09-18 18:38:39  \n",
       "3 2019-09-18 18:38:38  \n",
       "4 2019-09-18 18:38:38  \n",
       "5 2019-09-18 18:38:40  \n",
       "6 2019-09-18 18:38:41  \n",
       "7 2019-09-18 18:38:41  \n",
       "8 2019-09-18 18:38:42  \n",
       "9 2019-09-18 18:38:43  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-01T19:39:39.459 DEBUG iotfunctions.enginelog.configure_console_logging Console logging has been configured. Level = 10\n",
      "2019-10-01T19:39:39.461 DEBUG iotfunctions.metadata.__init__ Initializing new entity type using iotfunctions 2.0.3\n",
      "2019-10-01T19:39:39.462 DEBUG iotfunctions.pipeline.__init__ Starting trace\n",
      "2019-10-01T19:39:39.462 DEBUG iotfunctions.pipeline.__init__ Trace name: auto_trace_markus_testdata_20191001173939\n",
      "2019-10-01T19:39:39.463 DEBUG iotfunctions.pipeline.__init__ auto_save None\n",
      "2019-10-01T19:39:39.464 WARNING iotfunctions.metadata.__init__ No _db_schema specified in **kwargs. Usingdefault database schema.\n",
      "2019-10-01T19:39:39.464 DEBUG iotfunctions.util.categorize_args categorizing arguments\n",
      "2019-10-01T19:39:41.290 DEBUG iotfunctions.metadata.__init__ Initialized entity type \n",
      "EntityType:markus_testdata\n",
      "Functions:\n",
      "EntityDataGenerator at granularity None required inputs not evaluated yet outputs produced not evaluated yet on schedule None\n",
      "Granularities:\n",
      "No schedules metadata\n",
      "2019-10-01T19:39:41.292 DEBUG iotfunctions.metadata.generate_data Generating data for markus_testdata with metrics ['TestData'] and dimensions ['eventtype'] and dates []\n",
      "2019-10-01T19:39:41.306 DEBUG iotfunctions.automation.get_data Generated 6 rows of time series data from 2019-10-01 17:34:41.293838 to 2019-10-01 17:39:41.293838\n",
      "2019-10-01T19:39:42.872 INFO iotfunctions.db.write_frame Wrote data to table markus_testdata \n"
     ]
    }
   ],
   "source": [
    "# Generate 5 mins of data in table 'testdata' with a single additional column of TestData\n",
    "EngineLogging.configure_console_logging(logging.DEBUG)\n",
    "jobsettings = {}\n",
    "#jobsettings = {'_timestamp' : 'TIMESTAMP'}\n",
    "et = metadata.EntityType('markus_testdata', db, \n",
    "                         bif.EntityDataGenerator(output_item='my_test_gen'),\n",
    "                         \n",
    "                         Column('TestData',Float()),\n",
    "                         **jobsettings)\n",
    "\n",
    "#start_date = dt.datetime.utcnow() - dt.timedelta(days=1)\n",
    "#et.exec_local_pipeline(start_ts = start_date)\n",
    "df = et.generate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-01T19:54:51.542 DEBUG iotfunctions.metadata.__init__ Initializing new entity type using iotfunctions 2.0.3\n",
      "2019-10-01T19:54:51.543 DEBUG iotfunctions.pipeline.__init__ Starting trace\n",
      "2019-10-01T19:54:51.544 DEBUG iotfunctions.pipeline.__init__ Trace name: auto_trace_markus_testdata_20191001175451\n",
      "2019-10-01T19:54:51.544 DEBUG iotfunctions.pipeline.__init__ auto_save None\n",
      "2019-10-01T19:54:51.545 WARNING iotfunctions.metadata.__init__ No _db_schema specified in **kwargs. Usingdefault database schema.\n",
      "2019-10-01T19:54:51.546 DEBUG iotfunctions.util.categorize_args categorizing arguments\n",
      "2019-10-01T19:54:53.348 DEBUG iotfunctions.metadata.__init__ Initialized entity type \n",
      "EntityType:markus_testdata\n",
      "Functions:\n",
      "Granularities:\n",
      "No schedules metadata\n",
      "2019-10-01T19:54:53.767 DEBUG iotfunctions.metadata.index_df Indexed dataframe on id, evt_timestamp\n",
      "\n",
      "EntityType:markus_testdata\n",
      "Functions:\n",
      "Granularities:\n",
      "No schedules metadata\n"
     ]
    }
   ],
   "source": [
    "#jobsettings = {'_timestamp' : 'TIMESTAMP'}\n",
    "jobsettings = {}\n",
    "et2 = metadata.EntityType('markus_testdata', db, \n",
    "                          Column('TestData',Float()),\n",
    "                          **jobsettings)\n",
    "et2.get_data()\n",
    "print (et2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iotfunctions import pipeline as pp\n",
    "#job = pp.JobController(et)\n",
    "#job.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>field1</th>\n",
       "      <th>field3</th>\n",
       "      <th>field2</th>\n",
       "      <th>devicetype</th>\n",
       "      <th>deviceid</th>\n",
       "      <th>logicalinterface_id</th>\n",
       "      <th>eventtype</th>\n",
       "      <th>format</th>\n",
       "      <th>rcv_timestamp_utc</th>\n",
       "      <th>updated_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>True</td>\n",
       "      <td>field2 description</td>\n",
       "      <td>TYPE_7EQAJ</td>\n",
       "      <td>DEVICE_7EQAJ</td>\n",
       "      <td>5d82799ce24d7e0022912865</td>\n",
       "      <td>tree</td>\n",
       "      <td>json</td>\n",
       "      <td>2019-09-18 18:38:36.875</td>\n",
       "      <td>2019-09-18 18:38:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>172.0</td>\n",
       "      <td>False</td>\n",
       "      <td>field2 description</td>\n",
       "      <td>TYPE_7EQAJ</td>\n",
       "      <td>DEVICE_7EQAJ</td>\n",
       "      <td>5d82799ce24d7e0022912865</td>\n",
       "      <td>tree</td>\n",
       "      <td>json</td>\n",
       "      <td>2019-09-18 18:38:37.614</td>\n",
       "      <td>2019-09-18 18:38:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>771.0</td>\n",
       "      <td>False</td>\n",
       "      <td>field2 description</td>\n",
       "      <td>TYPE_7EQAJ</td>\n",
       "      <td>DEVICE_7EQAJ</td>\n",
       "      <td>5d82799ce24d7e0022912865</td>\n",
       "      <td>tree</td>\n",
       "      <td>json</td>\n",
       "      <td>2019-09-18 18:38:39.745</td>\n",
       "      <td>2019-09-18 18:38:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>940.0</td>\n",
       "      <td>True</td>\n",
       "      <td>field2 description</td>\n",
       "      <td>TYPE_7EQAJ</td>\n",
       "      <td>DEVICE_7EQAJ</td>\n",
       "      <td>5d82799ce24d7e0022912865</td>\n",
       "      <td>tree</td>\n",
       "      <td>json</td>\n",
       "      <td>2019-09-18 18:38:38.355</td>\n",
       "      <td>2019-09-18 18:38:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>910.0</td>\n",
       "      <td>True</td>\n",
       "      <td>field2 description</td>\n",
       "      <td>TYPE_7EQAJ</td>\n",
       "      <td>DEVICE_7EQAJ</td>\n",
       "      <td>5d82799ce24d7e0022912865</td>\n",
       "      <td>tree</td>\n",
       "      <td>json</td>\n",
       "      <td>2019-09-18 18:38:38.989</td>\n",
       "      <td>2019-09-18 18:38:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>580.0</td>\n",
       "      <td>True</td>\n",
       "      <td>field2 description</td>\n",
       "      <td>TYPE_7EQAJ</td>\n",
       "      <td>DEVICE_7EQAJ</td>\n",
       "      <td>5d82799ce24d7e0022912865</td>\n",
       "      <td>tree</td>\n",
       "      <td>json</td>\n",
       "      <td>2019-09-18 18:38:40.695</td>\n",
       "      <td>2019-09-18 18:38:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>710.0</td>\n",
       "      <td>False</td>\n",
       "      <td>field2 description</td>\n",
       "      <td>TYPE_7EQAJ</td>\n",
       "      <td>DEVICE_7EQAJ</td>\n",
       "      <td>5d82799ce24d7e0022912865</td>\n",
       "      <td>tree</td>\n",
       "      <td>json</td>\n",
       "      <td>2019-09-18 18:38:41.355</td>\n",
       "      <td>2019-09-18 18:38:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>240.0</td>\n",
       "      <td>False</td>\n",
       "      <td>field2 description</td>\n",
       "      <td>TYPE_7EQAJ</td>\n",
       "      <td>DEVICE_7EQAJ</td>\n",
       "      <td>5d82799ce24d7e0022912865</td>\n",
       "      <td>tree</td>\n",
       "      <td>json</td>\n",
       "      <td>2019-09-18 18:38:42.001</td>\n",
       "      <td>2019-09-18 18:38:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>921.0</td>\n",
       "      <td>False</td>\n",
       "      <td>field2 description</td>\n",
       "      <td>TYPE_7EQAJ</td>\n",
       "      <td>DEVICE_7EQAJ</td>\n",
       "      <td>5d82799ce24d7e0022912865</td>\n",
       "      <td>tree</td>\n",
       "      <td>json</td>\n",
       "      <td>2019-09-18 18:38:42.706</td>\n",
       "      <td>2019-09-18 18:38:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>319.0</td>\n",
       "      <td>False</td>\n",
       "      <td>field2 description</td>\n",
       "      <td>TYPE_7EQAJ</td>\n",
       "      <td>DEVICE_7EQAJ</td>\n",
       "      <td>5d82799ce24d7e0022912865</td>\n",
       "      <td>tree</td>\n",
       "      <td>json</td>\n",
       "      <td>2019-09-18 18:38:43.468</td>\n",
       "      <td>2019-09-18 18:38:43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   field1  field3              field2  devicetype      deviceid  \\\n",
       "0   540.0    True  field2 description  TYPE_7EQAJ  DEVICE_7EQAJ   \n",
       "1   172.0   False  field2 description  TYPE_7EQAJ  DEVICE_7EQAJ   \n",
       "2   771.0   False  field2 description  TYPE_7EQAJ  DEVICE_7EQAJ   \n",
       "3   940.0    True  field2 description  TYPE_7EQAJ  DEVICE_7EQAJ   \n",
       "4   910.0    True  field2 description  TYPE_7EQAJ  DEVICE_7EQAJ   \n",
       "5   580.0    True  field2 description  TYPE_7EQAJ  DEVICE_7EQAJ   \n",
       "6   710.0   False  field2 description  TYPE_7EQAJ  DEVICE_7EQAJ   \n",
       "7   240.0   False  field2 description  TYPE_7EQAJ  DEVICE_7EQAJ   \n",
       "8   921.0   False  field2 description  TYPE_7EQAJ  DEVICE_7EQAJ   \n",
       "9   319.0   False  field2 description  TYPE_7EQAJ  DEVICE_7EQAJ   \n",
       "\n",
       "        logicalinterface_id eventtype format       rcv_timestamp_utc  \\\n",
       "0  5d82799ce24d7e0022912865      tree   json 2019-09-18 18:38:36.875   \n",
       "1  5d82799ce24d7e0022912865      tree   json 2019-09-18 18:38:37.614   \n",
       "2  5d82799ce24d7e0022912865      tree   json 2019-09-18 18:38:39.745   \n",
       "3  5d82799ce24d7e0022912865      tree   json 2019-09-18 18:38:38.355   \n",
       "4  5d82799ce24d7e0022912865      tree   json 2019-09-18 18:38:38.989   \n",
       "5  5d82799ce24d7e0022912865      tree   json 2019-09-18 18:38:40.695   \n",
       "6  5d82799ce24d7e0022912865      tree   json 2019-09-18 18:38:41.355   \n",
       "7  5d82799ce24d7e0022912865      tree   json 2019-09-18 18:38:42.001   \n",
       "8  5d82799ce24d7e0022912865      tree   json 2019-09-18 18:38:42.706   \n",
       "9  5d82799ce24d7e0022912865      tree   json 2019-09-18 18:38:43.468   \n",
       "\n",
       "          updated_utc  \n",
       "0 2019-09-18 18:38:36  \n",
       "1 2019-09-18 18:38:37  \n",
       "2 2019-09-18 18:38:39  \n",
       "3 2019-09-18 18:38:38  \n",
       "4 2019-09-18 18:38:38  \n",
       "5 2019-09-18 18:38:40  \n",
       "6 2019-09-18 18:38:41  \n",
       "7 2019-09-18 18:38:41  \n",
       "8 2019-09-18 18:38:42  \n",
       "9 2019-09-18 18:38:43  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "markus_testdata\n",
      "(36, 8)\n"
     ]
    }
   ],
   "source": [
    "# read it back\n",
    "table = db.get_table(\"markus_testdata\")\n",
    "start_ts = dt.datetime.utcnow() - dt.timedelta(days=1)\n",
    "end_ts = dt.datetime.utcnow()\n",
    "df_in = db.read_table(table, None, None, None, \"evt_timestamp\", start_ts, end_ts)\n",
    "print (table)\n",
    "print (df_in.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deviceid</th>\n",
       "      <th>evt_timestamp</th>\n",
       "      <th>devicetype</th>\n",
       "      <th>logicalinterface_id</th>\n",
       "      <th>eventtype</th>\n",
       "      <th>format</th>\n",
       "      <th>updated_utc</th>\n",
       "      <th>TestData</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73004</td>\n",
       "      <td>2019-10-01 13:06:25.341693</td>\n",
       "      <td>markus_testdata</td>\n",
       "      <td></td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>-1.012887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73000</td>\n",
       "      <td>2019-10-01 13:07:25.341693</td>\n",
       "      <td>markus_testdata</td>\n",
       "      <td></td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>0.640831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73000</td>\n",
       "      <td>2019-10-01 13:08:25.341693</td>\n",
       "      <td>markus_testdata</td>\n",
       "      <td></td>\n",
       "      <td>yt</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>0.657694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73002</td>\n",
       "      <td>2019-10-01 13:09:25.341693</td>\n",
       "      <td>markus_testdata</td>\n",
       "      <td></td>\n",
       "      <td>tt</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>-2.390681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73004</td>\n",
       "      <td>2019-10-01 13:10:25.341693</td>\n",
       "      <td>markus_testdata</td>\n",
       "      <td></td>\n",
       "      <td>ne</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>-0.234181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>73000</td>\n",
       "      <td>2019-10-01 13:11:25.341693</td>\n",
       "      <td>markus_testdata</td>\n",
       "      <td></td>\n",
       "      <td>tt</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>0.952477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>73003</td>\n",
       "      <td>2019-10-01 13:12:27.737110</td>\n",
       "      <td>markus_testdata</td>\n",
       "      <td></td>\n",
       "      <td>ep</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>-0.107018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>73004</td>\n",
       "      <td>2019-10-01 13:13:27.737110</td>\n",
       "      <td>markus_testdata</td>\n",
       "      <td></td>\n",
       "      <td>te</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>-0.203514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>73003</td>\n",
       "      <td>2019-10-01 13:14:27.737110</td>\n",
       "      <td>markus_testdata</td>\n",
       "      <td></td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>0.720092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>73003</td>\n",
       "      <td>2019-10-01 13:15:27.737110</td>\n",
       "      <td>markus_testdata</td>\n",
       "      <td></td>\n",
       "      <td>vt</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>-1.720990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>73000</td>\n",
       "      <td>2019-10-01 13:16:27.737110</td>\n",
       "      <td>markus_testdata</td>\n",
       "      <td></td>\n",
       "      <td>et</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>1.520943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>73000</td>\n",
       "      <td>2019-10-01 13:17:27.737110</td>\n",
       "      <td>markus_testdata</td>\n",
       "      <td></td>\n",
       "      <td>ty</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>0.097358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>73000</td>\n",
       "      <td>2019-10-01 14:03:59.994715</td>\n",
       "      <td>markus_testdata</td>\n",
       "      <td></td>\n",
       "      <td>ey</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>0.521085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>73001</td>\n",
       "      <td>2019-10-01 14:04:59.994715</td>\n",
       "      <td>markus_testdata</td>\n",
       "      <td></td>\n",
       "      <td>et</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>1.059213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>73001</td>\n",
       "      <td>2019-10-01 14:05:59.994715</td>\n",
       "      <td>markus_testdata</td>\n",
       "      <td></td>\n",
       "      <td>et</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>0.064902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>73001</td>\n",
       "      <td>2019-10-01 14:06:59.994715</td>\n",
       "      <td>markus_testdata</td>\n",
       "      <td></td>\n",
       "      <td>tt</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>0.762488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>73002</td>\n",
       "      <td>2019-10-01 14:07:59.994715</td>\n",
       "      <td>markus_testdata</td>\n",
       "      <td></td>\n",
       "      <td>ye</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>-0.715103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>73001</td>\n",
       "      <td>2019-10-01 14:08:59.994715</td>\n",
       "      <td>markus_testdata</td>\n",
       "      <td></td>\n",
       "      <td>ey</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>2.103902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>73001</td>\n",
       "      <td>2019-10-01 14:07:29.501986</td>\n",
       "      <td>markus_testdata</td>\n",
       "      <td></td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>0.124766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>73001</td>\n",
       "      <td>2019-10-01 14:08:29.501986</td>\n",
       "      <td>markus_testdata</td>\n",
       "      <td></td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>0.014392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>73002</td>\n",
       "      <td>2019-10-01 14:09:29.501986</td>\n",
       "      <td>markus_testdata</td>\n",
       "      <td></td>\n",
       "      <td>et</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>0.359201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>73003</td>\n",
       "      <td>2019-10-01 14:10:29.501986</td>\n",
       "      <td>markus_testdata</td>\n",
       "      <td></td>\n",
       "      <td>tn</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>1.391642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>73000</td>\n",
       "      <td>2019-10-01 14:11:29.501986</td>\n",
       "      <td>markus_testdata</td>\n",
       "      <td></td>\n",
       "      <td>et</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>0.431859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>73003</td>\n",
       "      <td>2019-10-01 14:12:29.501986</td>\n",
       "      <td>markus_testdata</td>\n",
       "      <td></td>\n",
       "      <td>ye</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>0.889539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>73002</td>\n",
       "      <td>2019-10-01 14:11:56.729650</td>\n",
       "      <td>markus_testdata</td>\n",
       "      <td></td>\n",
       "      <td>ny</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>-0.150771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>73001</td>\n",
       "      <td>2019-10-01 14:12:56.729650</td>\n",
       "      <td>markus_testdata</td>\n",
       "      <td></td>\n",
       "      <td>ne</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>1.145375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>73004</td>\n",
       "      <td>2019-10-01 14:13:56.729650</td>\n",
       "      <td>markus_testdata</td>\n",
       "      <td></td>\n",
       "      <td>ee</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>0.144240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>73002</td>\n",
       "      <td>2019-10-01 14:14:56.729650</td>\n",
       "      <td>markus_testdata</td>\n",
       "      <td></td>\n",
       "      <td>tt</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>2.126168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>73004</td>\n",
       "      <td>2019-10-01 14:15:56.729650</td>\n",
       "      <td>markus_testdata</td>\n",
       "      <td></td>\n",
       "      <td>ny</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>-0.211232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>73004</td>\n",
       "      <td>2019-10-01 14:16:56.729650</td>\n",
       "      <td>markus_testdata</td>\n",
       "      <td></td>\n",
       "      <td>pt</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>0.753428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>73003</td>\n",
       "      <td>2019-10-01 14:13:53.168118</td>\n",
       "      <td>markus_testdata</td>\n",
       "      <td></td>\n",
       "      <td>te</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>0.392042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>73004</td>\n",
       "      <td>2019-10-01 14:14:53.168118</td>\n",
       "      <td>markus_testdata</td>\n",
       "      <td></td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>-0.288730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>73003</td>\n",
       "      <td>2019-10-01 14:15:53.168118</td>\n",
       "      <td>markus_testdata</td>\n",
       "      <td></td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>1.062992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>73004</td>\n",
       "      <td>2019-10-01 14:16:53.168118</td>\n",
       "      <td>markus_testdata</td>\n",
       "      <td></td>\n",
       "      <td>ee</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>0.635863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>73004</td>\n",
       "      <td>2019-10-01 14:17:53.168118</td>\n",
       "      <td>markus_testdata</td>\n",
       "      <td></td>\n",
       "      <td>nv</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>0.953396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>73002</td>\n",
       "      <td>2019-10-01 14:18:53.168118</td>\n",
       "      <td>markus_testdata</td>\n",
       "      <td></td>\n",
       "      <td>pe</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>-0.189876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   deviceid              evt_timestamp       devicetype logicalinterface_id  \\\n",
       "0     73004 2019-10-01 13:06:25.341693  markus_testdata                       \n",
       "1     73000 2019-10-01 13:07:25.341693  markus_testdata                       \n",
       "2     73000 2019-10-01 13:08:25.341693  markus_testdata                       \n",
       "3     73002 2019-10-01 13:09:25.341693  markus_testdata                       \n",
       "4     73004 2019-10-01 13:10:25.341693  markus_testdata                       \n",
       "5     73000 2019-10-01 13:11:25.341693  markus_testdata                       \n",
       "6     73003 2019-10-01 13:12:27.737110  markus_testdata                       \n",
       "7     73004 2019-10-01 13:13:27.737110  markus_testdata                       \n",
       "8     73003 2019-10-01 13:14:27.737110  markus_testdata                       \n",
       "9     73003 2019-10-01 13:15:27.737110  markus_testdata                       \n",
       "10    73000 2019-10-01 13:16:27.737110  markus_testdata                       \n",
       "11    73000 2019-10-01 13:17:27.737110  markus_testdata                       \n",
       "12    73000 2019-10-01 14:03:59.994715  markus_testdata                       \n",
       "13    73001 2019-10-01 14:04:59.994715  markus_testdata                       \n",
       "14    73001 2019-10-01 14:05:59.994715  markus_testdata                       \n",
       "15    73001 2019-10-01 14:06:59.994715  markus_testdata                       \n",
       "16    73002 2019-10-01 14:07:59.994715  markus_testdata                       \n",
       "17    73001 2019-10-01 14:08:59.994715  markus_testdata                       \n",
       "18    73001 2019-10-01 14:07:29.501986  markus_testdata                       \n",
       "19    73001 2019-10-01 14:08:29.501986  markus_testdata                       \n",
       "20    73002 2019-10-01 14:09:29.501986  markus_testdata                       \n",
       "21    73003 2019-10-01 14:10:29.501986  markus_testdata                       \n",
       "22    73000 2019-10-01 14:11:29.501986  markus_testdata                       \n",
       "23    73003 2019-10-01 14:12:29.501986  markus_testdata                       \n",
       "24    73002 2019-10-01 14:11:56.729650  markus_testdata                       \n",
       "25    73001 2019-10-01 14:12:56.729650  markus_testdata                       \n",
       "26    73004 2019-10-01 14:13:56.729650  markus_testdata                       \n",
       "27    73002 2019-10-01 14:14:56.729650  markus_testdata                       \n",
       "28    73004 2019-10-01 14:15:56.729650  markus_testdata                       \n",
       "29    73004 2019-10-01 14:16:56.729650  markus_testdata                       \n",
       "30    73003 2019-10-01 14:13:53.168118  markus_testdata                       \n",
       "31    73004 2019-10-01 14:14:53.168118  markus_testdata                       \n",
       "32    73003 2019-10-01 14:15:53.168118  markus_testdata                       \n",
       "33    73004 2019-10-01 14:16:53.168118  markus_testdata                       \n",
       "34    73004 2019-10-01 14:17:53.168118  markus_testdata                       \n",
       "35    73002 2019-10-01 14:18:53.168118  markus_testdata                       \n",
       "\n",
       "   eventtype format updated_utc  TestData  \n",
       "0         en               None -1.012887  \n",
       "1         en               None  0.640831  \n",
       "2         yt               None  0.657694  \n",
       "3         tt               None -2.390681  \n",
       "4         ne               None -0.234181  \n",
       "5         tt               None  0.952477  \n",
       "6         ep               None -0.107018  \n",
       "7         te               None -0.203514  \n",
       "8         en               None  0.720092  \n",
       "9         vt               None -1.720990  \n",
       "10        et               None  1.520943  \n",
       "11        ty               None  0.097358  \n",
       "12        ey               None  0.521085  \n",
       "13        et               None  1.059213  \n",
       "14        et               None  0.064902  \n",
       "15        tt               None  0.762488  \n",
       "16        ye               None -0.715103  \n",
       "17        ey               None  2.103902  \n",
       "18        en               None  0.124766  \n",
       "19        en               None  0.014392  \n",
       "20        et               None  0.359201  \n",
       "21        tn               None  1.391642  \n",
       "22        et               None  0.431859  \n",
       "23        ye               None  0.889539  \n",
       "24        ny               None -0.150771  \n",
       "25        ne               None  1.145375  \n",
       "26        ee               None  0.144240  \n",
       "27        tt               None  2.126168  \n",
       "28        ny               None -0.211232  \n",
       "29        pt               None  0.753428  \n",
       "30        te               None  0.392042  \n",
       "31        en               None -0.288730  \n",
       "32        en               None  1.062992  \n",
       "33        ee               None  0.635863  \n",
       "34        nv               None  0.953396  \n",
       "35        pe               None -0.189876  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# check whether the data for the last 5 minutes is the same - must return True\n",
    "print (np.array_equal(df['TestData'].tail(5), df_in['TestData'].tail(5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<iotfunctions.bif.EntityDataGenerator object at 0x7fb1b6515b00>]\n"
     ]
    }
   ],
   "source": [
    "print (et._functions)\n",
    "#del (et2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-01T20:37:21.472 DEBUG iotfunctions.metadata.__init__ Initializing new entity type using iotfunctions 2.0.3\n",
      "2019-10-01T20:37:21.473 DEBUG iotfunctions.pipeline.__init__ Starting trace\n",
      "2019-10-01T20:37:21.474 DEBUG iotfunctions.pipeline.__init__ Trace name: auto_trace_markus_testdata_20191001183721\n",
      "2019-10-01T20:37:21.474 DEBUG iotfunctions.pipeline.__init__ auto_save None\n",
      "2019-10-01T20:37:21.475 WARNING iotfunctions.metadata.__init__ No _db_schema specified in **kwargs. Usingdefault database schema.\n",
      "2019-10-01T20:37:21.475 DEBUG iotfunctions.util.categorize_args categorizing arguments\n",
      "2019-10-01T20:37:26.107 DEBUG iotfunctions.metadata.__init__ Initialized entity type \n",
      "EntityType:markus_testdata\n",
      "Functions:\n",
      "Granularities:\n",
      "No schedules metadata\n",
      "2019-10-01T20:37:26.109 DEBUG iotfunctions.base.parse_expression expression (5*df[\"TestData\"])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "jobsettings = {}\n",
    "et2 = metadata.EntityType('markus_testdata', db, \n",
    "                          Column('TestData',Float()),\n",
    "                          **jobsettings)\n",
    "et2._functions = [bif.PythonExpression('5*df[\"TestData\"]','TestOut')]\n",
    "\n",
    "# make sure the results of the python expression is saved to the derived metrics table\n",
    "et2._data_items.append({'columnName': 'TestOut', 'columnType': 'NUMBER', 'kpiFunctionId': 22856, \n",
    "                         'kpiFunctionDto': {'output': {'name': 'TestOut'}},\n",
    "                        'name': 'TestOut', 'parentDataItemName': None, 'sourceTableName': 'dm_markus_testdata',\n",
    "                        'transient': False,'type': 'DERIVED_METRIC'})\n",
    "# map device id to entity id for the derived metrics table\n",
    "et2._data_items.append({'columnName': 'deviceid', 'columnType': 'LITERAL', 'kpiFunctionId': None,\n",
    "                         'kpiFunctionDto': {},\n",
    "                         'name': 'ENTITY_ID', 'parentDataItemName': None,'sourceTableName': 'dm_markus_testdata',\n",
    "                         'transient': False,'type': 'METRIC'})\n",
    "\n",
    "# make sure the results of the python expression is saved to the derived metrics daily table\n",
    "et2._data_items.append({'columnName': 'TestData_max', 'columnType': 'NUMBER', 'kpiFunctionId': 22856, \n",
    "                         'kpiFunctionDto': {'output': {'name': 'TestData_max'}},\n",
    "                        'name': 'TestData_max', 'parentDataItemName': None, 'sourceTableName': 'dm_markus_testdata_daily',\n",
    "                        'transient': False,'type': 'DERIVED_METRIC'})\n",
    "# map device id to entity id for the derived metrics daily table\n",
    "et2._data_items.append({'columnName': 'deviceid', 'columnType': 'LITERAL', 'kpiFunctionId': None,\n",
    "                         'kpiFunctionDto': {},\n",
    "                         'name': 'ENTITY_ID', 'parentDataItemName': None,'sourceTableName': 'dm_markus_testdata_daily',\n",
    "                         'transient': False,'type': 'METRIC'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-01 13:06:25.341693\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "dt = datetime.datetime.strptime('2019-10-01 13:06:25.341693','%Y-%m-%d %H:%M:%S.%f')\n",
    "print (dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-01T20:38:07.542 DEBUG iotfunctions.pipeline.set_payload_params Setting param writer_name on payload to <class 'iotfunctions.pipeline.SqlAlchemyDataWriter'>\n",
      "2019-10-01T20:38:07.543 DEBUG iotfunctions.pipeline.set_payload_params Setting param db on payload to <iotfunctions.db.Database object at 0x7fb53c4ea978>\n",
      "2019-10-01T20:38:07.543 DEBUG iotfunctions.pipeline.set_payload_params Setting param _db_schema on payload to public\n",
      "2019-10-01T20:38:07.544 DEBUG iotfunctions.pipeline.set_payload_params Setting param save_trace_to_file on payload to True\n",
      "2019-10-01T20:38:07.544 DEBUG iotfunctions.pipeline.set_payload_params Setting param tenant_id on payload to AnalyticsServiceDev\n",
      "2019-10-01T20:38:08.279 DEBUG iotfunctions.pipeline.get_output_list The payload has candidate data items ['deviceid', 'evt_timestamp', 'TestData', 'deviceid', 'deviceid']. The DataReader has no projection list\n",
      "2019-10-01T20:38:08.281 DEBUG iotfunctions.metadata.classify_stages Input set was preset for function PythonExpression\n",
      "2019-10-01T20:38:08.283 DEBUG iotfunctions.metadata.classify_stages Output list set was preset for function PythonExpression\n",
      "2019-10-01T20:38:08.285 INFO iotfunctions.pipeline.__init__ Initialized job.\n",
      "\n",
      "2019-10-01T20:38:08.287 INFO iotfunctions.pipeline.__init__ \n",
      "Default schedule 5min \n",
      "    Schedule 5min start None:None backtracks: None \n",
      "Stages of type: get_data at grain None: \n",
      "   System generated DataReader stage: read_entity_data. Reads data from objects: markus_testdata\n",
      "Stages of type: transform at grain None: \n",
      "   PythonExpression at granularity None requires inputs {'TestData'} produces outputs ['TestOut'] on schedule 5min\n",
      "\n",
      "\n",
      "2019-10-01T20:38:08.289 INFO iotfunctions.enginelog.start_run_log Started logging into file run.log. Object Store path will be AnalyticsServiceDev/markus_testdata/20191001/183808_run.gz\n",
      "2019-10-01T20:38:08.290 DEBUG iotfunctions.pipeline.execute Starting execution number: 0 with execution date: 2019-10-01 18:38:08.289082\n",
      "2019-10-01T20:38:08.713 DEBUG iotfunctions.pipeline.get_next_execution_date Last execution of schedule 5min was 2019-10-01 18:37:26.704918. Next execution due 2019-10-01 18:42:26.704918.\n",
      "2019-10-01T20:38:08.714 DEBUG iotfunctions.pipeline.evaluate_schedules Schedule 5min will execute\n",
      "2019-10-01T20:38:08.715 DEBUG iotfunctions.pipeline.reset Started a new trace auto_trace_markus_testdata_20191001183808 \n",
      "2019-10-01T20:38:08.716 DEBUG iotfunctions.pipeline.reset Initiating auto save for trace\n",
      "2019-10-01T20:38:09.577 DEBUG iotfunctions.pipeline.insert Created job log entry (markus_testdata,5min): 2019-10-01 18:38:08.289082\n",
      "2019-10-01T20:38:09.578 DEBUG iotfunctions.pipeline.build_job_spec Building a job spec for schedule 5min with subsumbed schedules ['5min']\n",
      "2019-10-01T20:38:09.580 DEBUG iotfunctions.pipeline.build_stages_of_type Gathered stages of type get_data. Iteration 0: ['System generated DataReader stage: read_entity_data. Reads data from objects: markus_testdata']\n",
      "2019-10-01T20:38:09.582 DEBUG iotfunctions.pipeline.build_stages_of_type Built stages of type get_data\n",
      "2019-10-01T20:38:09.584 DEBUG iotfunctions.pipeline.build_stages_of_type Available columns: {'TestData', 'evt_timestamp', 'deviceid'}\n",
      "2019-10-01T20:38:09.586 DEBUG iotfunctions.pipeline.build_stages_of_type Gathered stages of type transform. Iteration 0: [\"PythonExpression at granularity None requires inputs {'TestData'} produces outputs ['TestOut'] on schedule 5min\"]\n",
      "2019-10-01T20:38:09.587 DEBUG iotfunctions.pipeline.build_stages_of_type Built stages of type transform\n",
      "2019-10-01T20:38:09.588 DEBUG iotfunctions.pipeline.build_stages_of_type Available columns: {'TestData', 'evt_timestamp', 'TestOut', 'deviceid'}\n",
      "2019-10-01T20:38:09.589 DEBUG iotfunctions.pipeline.build_job_spec Evaluating data source read_entity_data. Data items required from this source for this execution are {'TestData', 'evt_timestamp', 'deviceid'}\n",
      "2019-10-01T20:38:09.590 DEBUG iotfunctions.pipeline.build_job_spec Build of job spec is complete.\n",
      "2019-10-01T20:38:09.591 DEBUG iotfunctions.pipeline.build_job_spec -------------------------------\n",
      "2019-10-01T20:38:09.591 DEBUG iotfunctions.pipeline.build_job_spec skipped_stages: [None]\n",
      "2019-10-01T20:38:09.592 DEBUG iotfunctions.pipeline.build_job_spec input_level:\n",
      "2019-10-01T20:38:09.593 INFO iotfunctions.pipeline.build_job_spec   System generated DataReader stage: read_entity_data. Reads data from objects: markus_testdata\n",
      "2019-10-01T20:38:09.593 INFO iotfunctions.pipeline.build_job_spec   System generated DropNull stage\n",
      "2019-10-01T20:38:09.594 INFO iotfunctions.pipeline.build_job_spec   PythonExpression at granularity None requires inputs {'TestData'} produces outputs ['TestOut'] on schedule 5min\n",
      "2019-10-01T20:38:09.594 INFO iotfunctions.pipeline.build_job_spec   System generated SqlAlchemyDataWriter stage: markus_testdata_input_level\n",
      "2019-10-01T20:38:09.595 DEBUG iotfunctions.pipeline.build_job_spec -------------------------------\n",
      "TBD ***** - Add stages for usage stats and write to MessageHub\n",
      "2019-10-01T20:38:09.595 DEBUG iotfunctions.pipeline.exec_payload_method Returned default output for get_early_timestamp() on payload EntityType markus_testdata.  Default value is: None\n",
      "2019-10-01T20:38:09.596 DEBUG iotfunctions.pipeline.get_chunks The payload does not have an get_early_timestamp method or the method did not retrieve an early timestamp. Data will be retrieved in a single chunk\n",
      "2019-10-01T20:38:09.597 DEBUG iotfunctions.pipeline.write Processing as a single chunk\n",
      "2019-10-01T20:38:09.598 DEBUG iotfunctions.pipeline.write Executing stage read_entity_data.\n",
      "2019-10-01T20:38:10.041 DEBUG iotfunctions.metadata.index_df Indexed dataframe on id, evt_timestamp\n",
      "2019-10-01T20:38:10.043 DEBUG iotfunctions.pipeline.exec_stage_method No method get_column_map on read_entity_data returning default None. 'DataReader' object has no attribute 'get_column_map'\n",
      "2019-10-01T20:38:10.044 DEBUG iotfunctions.pipeline.merge_dataframe Merging dataframe with columns [] and index []\n",
      "2019-10-01T20:38:10.045 DEBUG iotfunctions.metadata.index_df Found existing index on id, evt_timestamp.No need to recreate index\n",
      "2019-10-01T20:38:10.047 INFO iotfunctions.pipeline.update_last_entry Trace message:  Completed stage.\n",
      "2019-10-01T20:38:10.048 INFO iotfunctions.pipeline.update_last_entry Trace payload: {'produces_output_items': True, 'output_items': ['deviceid', 'evt_timestamp', 'TestData', 'deviceid', 'deviceid'], 'discard_prior_data': False, 'merge_result': 'existing empty df with new DataFrame', 'usage': 210, 'index': ['id', 'evt_timestamp'], 'can_proceed': True, 'updated': datetime.datetime(2019, 10, 1, 18, 38, 10, 47317), 'cumulative_usage': 210}\n",
      "2019-10-01T20:38:10.049 DEBUG iotfunctions.pipeline.write Executing stage drop_null.\n",
      "2019-10-01T20:38:10.049 DEBUG iotfunctions.pipeline.execute columns excluded when dropping null rows ['deviceid', '_timestamp', 'logicalinterface_id', 'devicetype', 'format', 'updated_utc', 'evt_timestamp']\n",
      "2019-10-01T20:38:10.050 DEBUG iotfunctions.pipeline.execute columns considered when dropping null rows ['eventtype', 'TestData']\n",
      "2019-10-01T20:38:10.051 DEBUG iotfunctions.pipeline.execute eventtype count not null: 42\n",
      "2019-10-01T20:38:10.052 DEBUG iotfunctions.pipeline.execute TestData count not null: 42\n",
      "2019-10-01T20:38:10.058 DEBUG iotfunctions.pipeline.exec_stage_method No method get_column_map on drop_null returning default None. 'DropNull' object has no attribute 'get_column_map'\n",
      "2019-10-01T20:38:10.059 INFO iotfunctions.pipeline.update_last_entry Trace message:  Completed stage.\n",
      "2019-10-01T20:38:10.059 INFO iotfunctions.pipeline.update_last_entry Trace payload: {'produces_output_items': False, 'output_items': None, 'discard_prior_data': False, 'new_data_items_info': 'Function is configured not to produce any new data items  during execution', 'can_proceed': True, 'updated': datetime.datetime(2019, 10, 1, 18, 38, 10, 58941), 'cumulative_usage': 210}\n",
      "2019-10-01T20:38:10.060 DEBUG iotfunctions.pipeline.write Executing stage PythonExpression.\n",
      "2019-10-01T20:38:10.062 DEBUG iotfunctions.pipeline.execute Input dataframe has columns ['deviceid', 'devicetype', 'logicalinterface_id', 'eventtype', 'format', 'updated_utc', 'TestData', '_timestamp'] and index ['id', 'evt_timestamp']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-01T20:38:10.063 DEBUG iotfunctions.pipeline.merge_dataframe Merging dataframe with columns ['deviceid', 'devicetype', 'logicalinterface_id', 'eventtype', 'format', 'updated_utc', 'TestData', '_timestamp'] and index ['id', 'evt_timestamp']\n",
      "2019-10-01T20:38:10.064 DEBUG iotfunctions.pipeline.merge_dataframe Merging dataframe with the same index\n",
      "2019-10-01T20:38:10.068 INFO iotfunctions.pipeline.update_last_entry Trace message:  Completed stage.\n",
      "2019-10-01T20:38:10.069 INFO iotfunctions.pipeline.update_last_entry Trace payload: {'produces_output_items': True, 'output_items': ['TestOut'], 'discard_prior_data': False, 'merge_result': 'existing df with new DataFrame', 'usage': 42, 'can_proceed': True, 'updated': datetime.datetime(2019, 10, 1, 18, 38, 10, 68621), 'cumulative_usage': 252}\n",
      "2019-10-01T20:38:10.070 DEBUG iotfunctions.pipeline.write Executing stage markus_testdata_input_level.\n",
      "2019-10-01T20:38:10.071 DEBUG iotfunctions.pipeline.execute Data items will be written to database for interval (None, 2019-10-01 18:38:08.289082)\n",
      "2019-10-01T20:38:10.072 INFO iotfunctions.pipeline._get_active_cols_properties The column deviceid in data frame does not correspond to a data item. Therefore it is not written to the database.\n",
      "2019-10-01T20:38:10.073 INFO iotfunctions.pipeline._get_active_cols_properties The column devicetype in data frame does not correspond to a data item. Therefore it is not written to the database.\n",
      "2019-10-01T20:38:10.074 INFO iotfunctions.pipeline._get_active_cols_properties The column logicalinterface_id in data frame does not correspond to a data item. Therefore it is not written to the database.\n",
      "2019-10-01T20:38:10.075 INFO iotfunctions.pipeline._get_active_cols_properties The column eventtype in data frame does not correspond to a data item. Therefore it is not written to the database.\n",
      "2019-10-01T20:38:10.076 INFO iotfunctions.pipeline._get_active_cols_properties The column format in data frame does not correspond to a data item. Therefore it is not written to the database.\n",
      "2019-10-01T20:38:10.077 INFO iotfunctions.pipeline._get_active_cols_properties The column updated_utc in data frame does not correspond to a data item. Therefore it is not written to the database.\n",
      "2019-10-01T20:38:10.078 INFO iotfunctions.pipeline._get_active_cols_properties The column TestData in data frame does not correspond to a data item. Therefore it is not written to the database.\n",
      "2019-10-01T20:38:10.078 INFO iotfunctions.pipeline._get_active_cols_properties The column _timestamp in data frame does not correspond to a data item. Therefore it is not written to the database.\n",
      "2019-10-01T20:38:10.079 INFO iotfunctions.pipeline.execute The following data items will be written to the database: TestOut (dm_markus_testdata, NUMBER)\n",
      "2019-10-01T20:38:10.079 DEBUG iotfunctions.pipeline._get_table_properties Mapping between index name and index position: id -> 0, evt_timestamp -> 1\n",
      "2019-10-01T20:38:11.950 DEBUG iotfunctions.pipeline._get_table_properties For table dm_markus_testdata: delete statement: DELETE FROM dm_markus_testdata, insert statement: INSERT INTO dm_markus_testdata (entity_id, key, value_n, value_b, value_s, value_t, timestamp, last_update) VALUES (:entity_id, :key, :value_n, :value_b, :value_s, :value_t, :timestamp, :last_update)\n",
      "2019-10-01T20:38:11.951 DEBUG iotfunctions.pipeline._get_table_properties For table dm_markus_testdata: Mapping between column name and dataframe index position: ('entity_id', 0), ('timestamp', 1)\n",
      "2019-10-01T20:38:11.953 INFO iotfunctions.pipeline.execute The data items will be written into the following tables: dm_markus_testdata\n",
      "2019-10-01T20:38:11.955 DEBUG iotfunctions.pipeline._delete_old_data Deleting old data items from table dm_markus_testdata for time range [None, 2019-10-01 18:38:08.289082]\n",
      "2019-10-01T20:38:12.379 INFO iotfunctions.pipeline._delete_old_data 42 data items have been deleted from table dm_markus_testdata. Elapsed time in sec: 0.422\n",
      "entity_id 0 73004\n",
      "timestamp 1 2019-10-01 13:06:25.341693\n",
      "Persist row: ({'KEY': 'TestOut', 'entity_id': '73004', 'timestamp': Timestamp('2019-10-01 13:06:25.341693'), 'value_b': None, 'value_n': -5.0644348381579, 'value_s': None, 'value_t': None})\n",
      "entity_id 0 73000\n",
      "timestamp 1 2019-10-01 13:07:25.341693\n",
      "Persist row: ({'KEY': 'TestOut', 'entity_id': '73000', 'timestamp': Timestamp('2019-10-01 13:07:25.341693'), 'value_b': None, 'value_n': 3.20415341031487, 'value_s': None, 'value_t': None})\n",
      "entity_id 0 73000\n",
      "timestamp 1 2019-10-01 13:08:25.341693\n",
      "Persist row: ({'KEY': 'TestOut', 'entity_id': '73000', 'timestamp': Timestamp('2019-10-01 13:08:25.341693'), 'value_b': None, 'value_n': 3.288472301592825, 'value_s': None, 'value_t': None})\n",
      "entity_id 0 73002\n",
      "timestamp 1 2019-10-01 13:09:25.341693\n",
      "Persist row: ({'KEY': 'TestOut', 'entity_id': '73002', 'timestamp': Timestamp('2019-10-01 13:09:25.341693'), 'value_b': None, 'value_n': -11.95340660120565, 'value_s': None, 'value_t': None})\n",
      "entity_id 0 73004\n",
      "timestamp 1 2019-10-01 13:10:25.341693\n",
      "Persist row: ({'KEY': 'TestOut', 'entity_id': '73004', 'timestamp': Timestamp('2019-10-01 13:10:25.341693'), 'value_b': None, 'value_n': -1.170906559250285, 'value_s': None, 'value_t': None})\n",
      "entity_id 0 73000\n",
      "timestamp 1 2019-10-01 13:11:25.341693\n",
      "Persist row: ({'KEY': 'TestOut', 'entity_id': '73000', 'timestamp': Timestamp('2019-10-01 13:11:25.341693'), 'value_b': None, 'value_n': 4.762383994273965, 'value_s': None, 'value_t': None})\n",
      "entity_id 0 73003\n",
      "timestamp 1 2019-10-01 13:12:27.737110\n",
      "Persist row: ({'KEY': 'TestOut', 'entity_id': '73003', 'timestamp': Timestamp('2019-10-01 13:12:27.737110'), 'value_b': None, 'value_n': -0.5350879681619201, 'value_s': None, 'value_t': None})\n",
      "entity_id 0 73004\n",
      "timestamp 1 2019-10-01 13:13:27.737110\n",
      "Persist row: ({'KEY': 'TestOut', 'entity_id': '73004', 'timestamp': Timestamp('2019-10-01 13:13:27.737110'), 'value_b': None, 'value_n': -1.01757213687488, 'value_s': None, 'value_t': None})\n",
      "entity_id 0 73003\n",
      "timestamp 1 2019-10-01 13:14:27.737110\n",
      "Persist row: ({'KEY': 'TestOut', 'entity_id': '73003', 'timestamp': Timestamp('2019-10-01 13:14:27.737110'), 'value_b': None, 'value_n': 3.600460565290585, 'value_s': None, 'value_t': None})\n",
      "entity_id 0 73003\n",
      "timestamp 1 2019-10-01 13:15:27.737110\n",
      "Persist row: ({'KEY': 'TestOut', 'entity_id': '73003', 'timestamp': Timestamp('2019-10-01 13:15:27.737110'), 'value_b': None, 'value_n': -8.6049521438625, 'value_s': None, 'value_t': None})\n",
      "entity_id 0 73000\n",
      "timestamp 1 2019-10-01 13:16:27.737110\n",
      "Persist row: ({'KEY': 'TestOut', 'entity_id': '73000', 'timestamp': Timestamp('2019-10-01 13:16:27.737110'), 'value_b': None, 'value_n': 7.6047137496098, 'value_s': None, 'value_t': None})\n",
      "entity_id 0 73000\n",
      "timestamp 1 2019-10-01 13:17:27.737110\n",
      "Persist row: ({'KEY': 'TestOut', 'entity_id': '73000', 'timestamp': Timestamp('2019-10-01 13:17:27.737110'), 'value_b': None, 'value_n': 0.4867919086993205, 'value_s': None, 'value_t': None})\n",
      "entity_id 0 73000\n",
      "timestamp 1 2019-10-01 14:03:59.994715\n",
      "Persist row: ({'KEY': 'TestOut', 'entity_id': '73000', 'timestamp': Timestamp('2019-10-01 14:03:59.994715'), 'value_b': None, 'value_n': 2.60542356066652, 'value_s': None, 'value_t': None})\n",
      "entity_id 0 73001\n",
      "timestamp 1 2019-10-01 14:04:59.994715\n",
      "Persist row: ({'KEY': 'TestOut', 'entity_id': '73001', 'timestamp': Timestamp('2019-10-01 14:04:59.994715'), 'value_b': None, 'value_n': 5.296065070046, 'value_s': None, 'value_t': None})\n",
      "entity_id 0 73001\n",
      "timestamp 1 2019-10-01 14:05:59.994715\n",
      "Persist row: ({'KEY': 'TestOut', 'entity_id': '73001', 'timestamp': Timestamp('2019-10-01 14:05:59.994715'), 'value_b': None, 'value_n': 0.3245124130210665, 'value_s': None, 'value_t': None})\n",
      "entity_id 0 73001\n",
      "timestamp 1 2019-10-01 14:06:59.994715\n",
      "Persist row: ({'KEY': 'TestOut', 'entity_id': '73001', 'timestamp': Timestamp('2019-10-01 14:06:59.994715'), 'value_b': None, 'value_n': 3.812440036035235, 'value_s': None, 'value_t': None})\n",
      "entity_id 0 73002\n",
      "timestamp 1 2019-10-01 14:07:59.994715\n",
      "Persist row: ({'KEY': 'TestOut', 'entity_id': '73002', 'timestamp': Timestamp('2019-10-01 14:07:59.994715'), 'value_b': None, 'value_n': -3.575517468671385, 'value_s': None, 'value_t': None})\n",
      "entity_id 0 73001\n",
      "timestamp 1 2019-10-01 14:08:59.994715\n",
      "Persist row: ({'KEY': 'TestOut', 'entity_id': '73001', 'timestamp': Timestamp('2019-10-01 14:08:59.994715'), 'value_b': None, 'value_n': 10.5195101538445, 'value_s': None, 'value_t': None})\n",
      "entity_id 0 73001\n",
      "timestamp 1 2019-10-01 14:07:29.501986\n",
      "Persist row: ({'KEY': 'TestOut', 'entity_id': '73001', 'timestamp': Timestamp('2019-10-01 14:07:29.501986'), 'value_b': None, 'value_n': 0.62383051747377, 'value_s': None, 'value_t': None})\n",
      "entity_id 0 73001\n",
      "timestamp 1 2019-10-01 14:08:29.501986\n",
      "Persist row: ({'KEY': 'TestOut', 'entity_id': '73001', 'timestamp': Timestamp('2019-10-01 14:08:29.501986'), 'value_b': None, 'value_n': 0.0719600578793825, 'value_s': None, 'value_t': None})\n",
      "entity_id 0 73002\n",
      "timestamp 1 2019-10-01 14:09:29.501986\n",
      "Persist row: ({'KEY': 'TestOut', 'entity_id': '73002', 'timestamp': Timestamp('2019-10-01 14:09:29.501986'), 'value_b': None, 'value_n': 1.796007025959045, 'value_s': None, 'value_t': None})\n",
      "entity_id 0 73003\n",
      "timestamp 1 2019-10-01 14:10:29.501986\n",
      "Persist row: ({'KEY': 'TestOut', 'entity_id': '73003', 'timestamp': Timestamp('2019-10-01 14:10:29.501986'), 'value_b': None, 'value_n': 6.95820990104535, 'value_s': None, 'value_t': None})\n",
      "entity_id 0 73000\n",
      "timestamp 1 2019-10-01 14:11:29.501986\n",
      "Persist row: ({'KEY': 'TestOut', 'entity_id': '73000', 'timestamp': Timestamp('2019-10-01 14:11:29.501986'), 'value_b': None, 'value_n': 2.1592949178958603, 'value_s': None, 'value_t': None})\n",
      "entity_id 0 73003\n",
      "timestamp 1 2019-10-01 14:12:29.501986\n",
      "Persist row: ({'KEY': 'TestOut', 'entity_id': '73003', 'timestamp': Timestamp('2019-10-01 14:12:29.501986'), 'value_b': None, 'value_n': 4.44769496332397, 'value_s': None, 'value_t': None})\n",
      "entity_id 0 73002\n",
      "timestamp 1 2019-10-01 14:11:56.729650\n",
      "Persist row: ({'KEY': 'TestOut', 'entity_id': '73002', 'timestamp': Timestamp('2019-10-01 14:11:56.729650'), 'value_b': None, 'value_n': -0.7538534346346, 'value_s': None, 'value_t': None})\n",
      "entity_id 0 73001\n",
      "timestamp 1 2019-10-01 14:12:56.729650\n",
      "Persist row: ({'KEY': 'TestOut', 'entity_id': '73001', 'timestamp': Timestamp('2019-10-01 14:12:56.729650'), 'value_b': None, 'value_n': 5.72687725279215, 'value_s': None, 'value_t': None})\n",
      "entity_id 0 73004\n",
      "timestamp 1 2019-10-01 14:13:56.729650\n",
      "Persist row: ({'KEY': 'TestOut', 'entity_id': '73004', 'timestamp': Timestamp('2019-10-01 14:13:56.729650'), 'value_b': None, 'value_n': 0.7212024786674, 'value_s': None, 'value_t': None})\n",
      "entity_id 0 73002\n",
      "timestamp 1 2019-10-01 14:14:56.729650\n",
      "Persist row: ({'KEY': 'TestOut', 'entity_id': '73002', 'timestamp': Timestamp('2019-10-01 14:14:56.729650'), 'value_b': None, 'value_n': 10.63083872577935, 'value_s': None, 'value_t': None})\n",
      "entity_id 0 73004\n",
      "timestamp 1 2019-10-01 14:15:56.729650\n",
      "Persist row: ({'KEY': 'TestOut', 'entity_id': '73004', 'timestamp': Timestamp('2019-10-01 14:15:56.729650'), 'value_b': None, 'value_n': -1.05616145214809, 'value_s': None, 'value_t': None})\n",
      "entity_id 0 73004\n",
      "timestamp 1 2019-10-01 14:16:56.729650\n",
      "Persist row: ({'KEY': 'TestOut', 'entity_id': '73004', 'timestamp': Timestamp('2019-10-01 14:16:56.729650'), 'value_b': None, 'value_n': 3.76714218134554, 'value_s': None, 'value_t': None})\n",
      "entity_id 0 73003\n",
      "timestamp 1 2019-10-01 14:13:53.168118\n",
      "Persist row: ({'KEY': 'TestOut', 'entity_id': '73003', 'timestamp': Timestamp('2019-10-01 14:13:53.168118'), 'value_b': None, 'value_n': 1.960208418928965, 'value_s': None, 'value_t': None})\n",
      "entity_id 0 73004\n",
      "timestamp 1 2019-10-01 14:14:53.168118\n",
      "Persist row: ({'KEY': 'TestOut', 'entity_id': '73004', 'timestamp': Timestamp('2019-10-01 14:14:53.168118'), 'value_b': None, 'value_n': -1.44364964174579, 'value_s': None, 'value_t': None})\n",
      "entity_id 0 73003\n",
      "timestamp 1 2019-10-01 14:15:53.168118\n",
      "Persist row: ({'KEY': 'TestOut', 'entity_id': '73003', 'timestamp': Timestamp('2019-10-01 14:15:53.168118'), 'value_b': None, 'value_n': 5.31495880150525, 'value_s': None, 'value_t': None})\n",
      "entity_id 0 73004\n",
      "timestamp 1 2019-10-01 14:16:53.168118\n",
      "Persist row: ({'KEY': 'TestOut', 'entity_id': '73004', 'timestamp': Timestamp('2019-10-01 14:16:53.168118'), 'value_b': None, 'value_n': 3.17931254145455, 'value_s': None, 'value_t': None})\n",
      "entity_id 0 73004\n",
      "timestamp 1 2019-10-01 14:17:53.168118\n",
      "Persist row: ({'KEY': 'TestOut', 'entity_id': '73004', 'timestamp': Timestamp('2019-10-01 14:17:53.168118'), 'value_b': None, 'value_n': 4.766980683322015, 'value_s': None, 'value_t': None})\n",
      "entity_id 0 73002\n",
      "timestamp 1 2019-10-01 14:18:53.168118\n",
      "Persist row: ({'KEY': 'TestOut', 'entity_id': '73002', 'timestamp': Timestamp('2019-10-01 14:18:53.168118'), 'value_b': None, 'value_n': -0.9493781996990449, 'value_s': None, 'value_t': None})\n",
      "entity_id 0 73002\n",
      "timestamp 1 2019-10-01 17:34:41.293838\n",
      "Persist row: ({'KEY': 'TestOut', 'entity_id': '73002', 'timestamp': Timestamp('2019-10-01 17:34:41.293838'), 'value_b': None, 'value_n': 1.7336707492094798, 'value_s': None, 'value_t': None})\n",
      "entity_id 0 73001\n",
      "timestamp 1 2019-10-01 17:35:41.293838\n",
      "Persist row: ({'KEY': 'TestOut', 'entity_id': '73001', 'timestamp': Timestamp('2019-10-01 17:35:41.293838'), 'value_b': None, 'value_n': -1.430034203721585, 'value_s': None, 'value_t': None})\n",
      "entity_id 0 73002\n",
      "timestamp 1 2019-10-01 17:36:41.293838\n",
      "Persist row: ({'KEY': 'TestOut', 'entity_id': '73002', 'timestamp': Timestamp('2019-10-01 17:36:41.293838'), 'value_b': None, 'value_n': 5.9752525405135, 'value_s': None, 'value_t': None})\n",
      "entity_id 0 73004\n",
      "timestamp 1 2019-10-01 17:37:41.293838\n",
      "Persist row: ({'KEY': 'TestOut', 'entity_id': '73004', 'timestamp': Timestamp('2019-10-01 17:37:41.293838'), 'value_b': None, 'value_n': -3.18338511871712, 'value_s': None, 'value_t': None})\n",
      "entity_id 0 73000\n",
      "timestamp 1 2019-10-01 17:38:41.293838\n",
      "Persist row: ({'KEY': 'TestOut', 'entity_id': '73000', 'timestamp': Timestamp('2019-10-01 17:38:41.293838'), 'value_b': None, 'value_n': 3.2175641511292303, 'value_s': None, 'value_t': None})\n",
      "entity_id 0 73000\n",
      "timestamp 1 2019-10-01 17:39:41.293838\n",
      "Persist row: ({'KEY': 'TestOut', 'entity_id': '73000', 'timestamp': Timestamp('2019-10-01 17:39:41.293838'), 'value_b': None, 'value_n': 0.14305745710874698, 'value_s': None, 'value_t': None})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-01T20:38:19.008 INFO iotfunctions.pipeline._persist_data Number of data item values persisted so far: 42 (dm_markus_testdata)\n",
      "2019-10-01T20:38:19.009 INFO iotfunctions.pipeline._persist_data Total number of persisted data item values: 42, Elapsed time in sec: 6.628, SqlAlchemy time in sec: 6.613\n",
      "2019-10-01T20:38:19.009 DEBUG iotfunctions.pipeline.exec_stage_method No method get_column_map on markus_testdata_input_level returning default None. 'SqlAlchemyDataWriter' object has no attribute 'get_column_map'\n",
      "2019-10-01T20:38:19.010 INFO iotfunctions.pipeline.update_last_entry Trace message:  Completed stage.\n",
      "2019-10-01T20:38:19.011 INFO iotfunctions.pipeline.update_last_entry Trace payload: {'produces_output_items': False, 'output_items': None, 'discard_prior_data': False, 'new_data_items_info': 'Function is configured not to produce any new data items  during execution', 'can_proceed': True, 'updated': datetime.datetime(2019, 10, 1, 18, 38, 19, 10389), 'cumulative_usage': 252}\n",
      "2019-10-01T20:38:19.014 INFO iotfunctions.pipeline.write Execution complete\n",
      "2019-10-01T20:38:19.017 DEBUG urllib3.connectionpool._new_conn Starting new HTTPS connection (1): s3-api.us-geo.objectstorage.softlayer.net\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markus/.local/lib/python3.7/site-packages/urllib3/connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-01T20:38:19.880 DEBUG urllib3.connectionpool._make_request https://s3-api.us-geo.objectstorage.softlayer.net:443 \"PUT /analytics-runtime-analyticsservicedev-799d2008b460/AnalyticsServiceDev/markus_testdata/20191001/markus_testdata_trace_183808 HTTP/1.1\" 200 0\n",
      "2019-10-01T20:38:19.882 DEBUG iotfunctions.pipeline.save Saved trace to cos AnalyticsServiceDev/markus_testdata/20191001/markus_testdata_trace_183808\n",
      "2019-10-01T20:38:19.885 DEBUG iotfunctions.pipeline.save wrote trace to file auto_trace_markus_testdata_20191001183808.json\n",
      "2019-10-01T20:38:20.312 DEBUG iotfunctions.pipeline.update Updated job log (markus_testdata,5min): 2019-10-01 18:38:08.289082\n",
      "2019-10-01T20:38:20.313 DEBUG iotfunctions.pipeline.get_next_future_execution Next scheduled execution date is 2019-10-01 18:43:08.289082\n",
      "2019-10-01T20:38:20.315 DEBUG iotfunctions.pipeline.execute Ending job normally as there are no scheduled executions  due before execution end time\n",
      "2019-10-01T20:38:20.340 DEBUG iotfunctions.pipeline.run_auto_save auto_trace_markus_testdata_20191001183808 autosave thread has stopped\n",
      "2019-10-01T20:38:20.341 DEBUG iotfunctions.pipeline.stop Stopping autosave on trace auto_trace_markus_testdata_20191001183808\n"
     ]
    }
   ],
   "source": [
    "# dm_markus_testdate MUST exist, so run the following sql statment in DBeaver\n",
    "#     - Db2 ----\n",
    "#CREATE TABLE BLUADMIN.DM_MARKUS_TESTDATA (\n",
    "#  entity_id varchar(255),\n",
    "#  key varchar(255),\n",
    "#  value_n double,\n",
    "#  value_b boolean,\n",
    "#  value_s varchar(255),\n",
    "#  value_t timestamp,\n",
    "#  timestamp timestamp,\n",
    "#  last_update timestamp\n",
    "# );\n",
    "\n",
    "#    - Postgres ---\n",
    "#CREATE TABLE public.dm_markus_testdata (\n",
    "#  entity_id varchar(255),\n",
    "#  key varchar(255),\n",
    "#  value_n double precision,\n",
    "#  value_b boolean,\n",
    "#  value_s varchar(255),\n",
    "#  value_t timestamp,\n",
    "#  timestamp timestamp,\n",
    "#  last_update timestamp\n",
    "# );\n",
    "\n",
    "\n",
    "# The commented out version just dumps the job spec\n",
    "#jobsettings = {'writer_name' : SqlAlchemyDataWriter, 'db': db, '_db_schema': 'BLUADMIN', 'save_trace_to_file' : True}\n",
    "jobsettings = {'writer_name' : SqlAlchemyDataWriter, 'db': db, '_db_schema': 'public', 'save_trace_to_file' : True}\n",
    "job = pp.JobController(et2, **jobsettings)\n",
    "job.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'deviceid', 'type': 'METRIC', 'parentDataItem': None, 'kpiFunctionDto': None, 'columnName': 'deviceid', 'columnType': 'LITERAL', 'sourceTableName': 'markus_testdata', 'tags': [], 'transient': False}, {'name': 'evt_timestamp', 'type': 'METRIC', 'parentDataItem': None, 'kpiFunctionDto': None, 'columnName': 'evt_timestamp', 'columnType': 'TIMESTAMP', 'sourceTableName': 'markus_testdata', 'tags': [], 'transient': False}, {'name': 'TestData', 'type': 'METRIC', 'parentDataItem': None, 'kpiFunctionDto': None, 'columnName': 'TestData', 'columnType': 'NUMBER', 'sourceTableName': 'markus_testdata', 'tags': [], 'transient': False}, {'columnName': 'TestOut', 'columnType': 'NUMBER', 'kpiFunctionId': 22856, 'kpiFunctionDto': {'output': {'name': 'TestOut'}}, 'name': 'TestOut', 'parentDataItemName': None, 'sourceTableName': 'dm_markus_testdata', 'transient': False, 'type': 'DERIVED_METRIC'}, {'columnName': 'deviceid', 'columnType': 'LITERAL', 'kpiFunctionId': None, 'kpiFunctionDto': {}, 'name': 'ENTITY_ID', 'parentDataItemName': None, 'sourceTableName': 'dm_markus_testdata', 'transient': False, 'type': 'METRIC'}, {'columnName': 'TestData_max', 'columnType': 'NUMBER', 'kpiFunctionId': 22856, 'kpiFunctionDto': {'output': {'name': 'TestData_max'}}, 'name': 'TestData_max', 'parentDataItemName': None, 'sourceTableName': 'dm_markus_testdata_daily', 'transient': False, 'type': 'DERIVED_METRIC'}, {'columnName': 'deviceid', 'columnType': 'LITERAL', 'kpiFunctionId': None, 'kpiFunctionDto': {}, 'name': 'ENTITY_ID', 'parentDataItemName': None, 'sourceTableName': 'dm_markus_testdata_daily', 'transient': False, 'type': 'METRIC'}]\n"
     ]
    }
   ],
   "source": [
    "print (et2.get_data_items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-01T16:25:34.066 DEBUG iotfunctions.pipeline.set_payload_params Setting param writer_name on payload to <class 'iotfunctions.pipeline.SqlAlchemyDataWriter'>\n",
      "2019-10-01T16:25:34.067 DEBUG iotfunctions.pipeline.set_payload_params Setting param _db_schema on payload to public\n",
      "2019-10-01T16:25:34.068 DEBUG iotfunctions.pipeline.set_payload_params Setting param save_trace_to_file on payload to True\n",
      "2019-10-01T16:25:34.069 DEBUG iotfunctions.pipeline.set_payload_params Setting param tenant_id on payload to AnalyticsServiceDev\n",
      "2019-10-01T16:25:34.938 DEBUG iotfunctions.pipeline.get_output_list The payload has candidate data items ['deviceid', 'evt_timestamp', 'TestData', 'deviceid', 'deviceid']. The DataReader has no projection list\n",
      "2019-10-01T16:25:34.939 DEBUG iotfunctions.metadata.classify_stages Output list set was preset for function AggregateItems\n",
      "2019-10-01T16:25:34.941 DEBUG iotfunctions.metadata.classify_stages Function AggregateItems has no _metadata_params property. This property allows the stage to add properties to the entity type. Using default of {}\n",
      "2019-10-01T16:25:34.943 INFO iotfunctions.pipeline.__init__ Initialized job.\n",
      "\n",
      "2019-10-01T16:25:34.946 INFO iotfunctions.pipeline.__init__ \n",
      "Default schedule 5min \n",
      "    Schedule 5min start None:None backtracks: None \n",
      "Stages of type: get_data at grain None: \n",
      "   System generated DataReader stage: read_entity_data. Reads data from objects: markus_testdata\n",
      "Stages of type: simple_aggregate at grain daily: \n",
      "   <iotfunctions.pipeline.AggregateItems object at 0x7fb1b61e4d30>\n",
      "\n",
      "\n",
      "2019-10-01T16:25:34.948 INFO iotfunctions.enginelog.start_run_log Started logging into file run.log. Object Store path will be AnalyticsServiceDev/markus_testdata/20191001/142534_run.gz\n",
      "2019-10-01T16:25:34.949 DEBUG iotfunctions.pipeline.execute Starting execution number: 0 with execution date: 2019-10-01 14:25:34.947989\n",
      "2019-10-01T16:25:35.374 DEBUG iotfunctions.pipeline.get_next_execution_date Last execution of schedule 5min was 2019-10-01 14:23:30.599293. Next execution due 2019-10-01 14:28:30.599293.\n",
      "2019-10-01T16:25:35.375 DEBUG iotfunctions.pipeline.evaluate_schedules Schedule 5min will execute\n",
      "2019-10-01T16:25:35.376 DEBUG iotfunctions.pipeline.reset Started a new trace auto_trace_markus_testdata_20191001142534 \n",
      "2019-10-01T16:25:35.377 DEBUG iotfunctions.pipeline.reset Initiating auto save for trace\n",
      "2019-10-01T16:25:36.238 DEBUG iotfunctions.pipeline.insert Created job log entry (markus_testdata,5min): 2019-10-01 14:25:34.947989\n",
      "2019-10-01T16:25:36.242 DEBUG iotfunctions.pipeline.build_job_spec Building a job spec for schedule 5min with subsumbed schedules ['5min']\n",
      "2019-10-01T16:25:36.244 DEBUG iotfunctions.pipeline.build_stages_of_type Gathered stages of type get_data. Iteration 0: ['System generated DataReader stage: read_entity_data. Reads data from objects: markus_testdata']\n",
      "2019-10-01T16:25:36.246 DEBUG iotfunctions.pipeline.build_stages_of_type Built stages of type get_data\n",
      "2019-10-01T16:25:36.247 DEBUG iotfunctions.pipeline.build_stages_of_type Available columns: {'deviceid', 'evt_timestamp', 'TestData'}\n",
      "2019-10-01T16:25:36.249 DEBUG iotfunctions.pipeline.build_stages_of_type Built stages of type transform\n",
      "2019-10-01T16:25:36.250 DEBUG iotfunctions.pipeline.build_stages_of_type Available columns: {'deviceid', 'evt_timestamp', 'TestData'}\n",
      "2019-10-01T16:25:36.250 DEBUG iotfunctions.pipeline.build_job_spec Building job spec for aggregation to grain: daily\n",
      "2019-10-01T16:25:36.251 DEBUG iotfunctions.pipeline.build_job_spec Collapsed aggregation stages ['AggregateItems'] down to a single\"\n",
      "2019-10-01T16:25:36.252 DEBUG iotfunctions.pipeline.build_job_spec OrderedDict([('TestData', ['max'])])\n",
      "2019-10-01T16:25:36.252 DEBUG iotfunctions.pipeline.build_job_spec Added aggregregator to job spec: Aggregator: auto_aggregate with granularity: daily.  Aggregates TestData using ['max'] .\n",
      "2019-10-01T16:25:36.254 DEBUG iotfunctions.pipeline.build_stages_of_type Built stages of type transform\n",
      "2019-10-01T16:25:36.254 DEBUG iotfunctions.pipeline.build_stages_of_type Available columns: {'evt_timestamp', 'TestData_max', 'deviceid', 'TestData'}\n",
      "2019-10-01T16:25:36.255 DEBUG iotfunctions.pipeline.build_job_spec Completed job spec build for grain: daily\n",
      "2019-10-01T16:25:36.256 DEBUG iotfunctions.pipeline.build_job_spec Evaluating data source read_entity_data. Data items required from this source for this execution are {'evt_timestamp', 'deviceid', 'TestData'}\n",
      "2019-10-01T16:25:36.257 DEBUG iotfunctions.pipeline.build_job_spec Build of job spec is complete.\n",
      "2019-10-01T16:25:36.257 DEBUG iotfunctions.pipeline.build_job_spec -------------------------------\n",
      "2019-10-01T16:25:36.258 DEBUG iotfunctions.pipeline.build_job_spec skipped_stages: [None]\n",
      "2019-10-01T16:25:36.258 DEBUG iotfunctions.pipeline.build_job_spec input_level:\n",
      "2019-10-01T16:25:36.259 INFO iotfunctions.pipeline.build_job_spec   System generated DataReader stage: read_entity_data. Reads data from objects: markus_testdata\n",
      "2019-10-01T16:25:36.259 INFO iotfunctions.pipeline.build_job_spec   System generated DropNull stage\n",
      "2019-10-01T16:25:36.260 INFO iotfunctions.pipeline.build_job_spec   System generated SqlAlchemyDataWriter stage: markus_testdata_input_level\n",
      "2019-10-01T16:25:36.261 DEBUG iotfunctions.pipeline.build_job_spec daily:\n",
      "2019-10-01T16:25:36.261 INFO iotfunctions.pipeline.build_job_spec   Aggregator: auto_aggregate with granularity: daily.  Aggregates TestData using ['max'] .\n",
      "2019-10-01T16:25:36.262 INFO iotfunctions.pipeline.build_job_spec   System generated SqlAlchemyDataWriter stage: markus_testdata_daily\n",
      "2019-10-01T16:25:36.263 DEBUG iotfunctions.pipeline.build_job_spec -------------------------------\n",
      "TBD ***** - Add stages for usage stats and write to MessageHub\n",
      "2019-10-01T16:25:36.264 DEBUG iotfunctions.pipeline.exec_payload_method Returned default output for get_early_timestamp() on payload EntityType markus_testdata.  Default value is: None\n",
      "2019-10-01T16:25:36.265 DEBUG iotfunctions.pipeline.get_chunks The payload does not have an get_early_timestamp method or the method did not retrieve an early timestamp. Data will be retrieved in a single chunk\n",
      "2019-10-01T16:25:36.266 DEBUG iotfunctions.pipeline.write Processing as a single chunk\n",
      "2019-10-01T16:25:36.268 DEBUG iotfunctions.pipeline.write Executing stage read_entity_data.\n",
      "2019-10-01T16:25:36.710 DEBUG iotfunctions.metadata.index_df Indexed dataframe on id, evt_timestamp\n",
      "2019-10-01T16:25:36.711 DEBUG iotfunctions.pipeline.exec_stage_method No method get_column_map on read_entity_data returning default None. 'DataReader' object has no attribute 'get_column_map'\n",
      "2019-10-01T16:25:36.712 DEBUG iotfunctions.pipeline.merge_dataframe Merging dataframe with columns [] and index []\n",
      "2019-10-01T16:25:36.713 DEBUG iotfunctions.metadata.index_df Found existing index on id, evt_timestamp.No need to recreate index\n",
      "2019-10-01T16:25:36.714 INFO iotfunctions.pipeline.update_last_entry Trace message:  Completed stage.\n",
      "2019-10-01T16:25:36.714 INFO iotfunctions.pipeline.update_last_entry Trace payload: {'produces_output_items': True, 'output_items': ['deviceid', 'evt_timestamp', 'TestData', 'deviceid', 'deviceid'], 'discard_prior_data': False, 'merge_result': 'existing empty df with new DataFrame', 'usage': 180, 'index': ['id', 'evt_timestamp'], 'can_proceed': True, 'updated': datetime.datetime(2019, 10, 1, 14, 25, 36, 714059), 'cumulative_usage': 180}\n",
      "2019-10-01T16:25:36.715 DEBUG iotfunctions.pipeline.write Executing stage drop_null.\n",
      "2019-10-01T16:25:36.716 DEBUG iotfunctions.pipeline.execute columns excluded when dropping null rows ['deviceid', '_timestamp', 'logicalinterface_id', 'devicetype', 'format', 'updated_utc', 'evt_timestamp']\n",
      "2019-10-01T16:25:36.716 DEBUG iotfunctions.pipeline.execute columns considered when dropping null rows ['eventtype', 'TestData']\n",
      "2019-10-01T16:25:36.717 DEBUG iotfunctions.pipeline.execute eventtype count not null: 36\n",
      "2019-10-01T16:25:36.718 DEBUG iotfunctions.pipeline.execute TestData count not null: 36\n",
      "2019-10-01T16:25:36.722 DEBUG iotfunctions.pipeline.exec_stage_method No method get_column_map on drop_null returning default None. 'DropNull' object has no attribute 'get_column_map'\n",
      "2019-10-01T16:25:36.723 INFO iotfunctions.pipeline.update_last_entry Trace message:  Completed stage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-01T16:25:36.723 INFO iotfunctions.pipeline.update_last_entry Trace payload: {'produces_output_items': False, 'output_items': None, 'discard_prior_data': False, 'new_data_items_info': 'Function is configured not to produce any new data items  during execution', 'can_proceed': True, 'updated': datetime.datetime(2019, 10, 1, 14, 25, 36, 723347), 'cumulative_usage': 180}\n",
      "2019-10-01T16:25:36.724 DEBUG iotfunctions.pipeline.write Executing stage markus_testdata_input_level.\n",
      "2019-10-01T16:25:36.725 DEBUG iotfunctions.pipeline.execute Data items will be written to database for interval (None, 2019-10-01 14:25:34.947989)\n",
      "2019-10-01T16:25:36.725 INFO iotfunctions.pipeline._get_active_cols_properties The column deviceid in data frame does not correspond to a data item. Therefore it is not written to the database.\n",
      "2019-10-01T16:25:36.726 INFO iotfunctions.pipeline._get_active_cols_properties The column devicetype in data frame does not correspond to a data item. Therefore it is not written to the database.\n",
      "2019-10-01T16:25:36.726 INFO iotfunctions.pipeline._get_active_cols_properties The column logicalinterface_id in data frame does not correspond to a data item. Therefore it is not written to the database.\n",
      "2019-10-01T16:25:36.727 INFO iotfunctions.pipeline._get_active_cols_properties The column eventtype in data frame does not correspond to a data item. Therefore it is not written to the database.\n",
      "2019-10-01T16:25:36.727 INFO iotfunctions.pipeline._get_active_cols_properties The column format in data frame does not correspond to a data item. Therefore it is not written to the database.\n",
      "2019-10-01T16:25:36.728 INFO iotfunctions.pipeline._get_active_cols_properties The column updated_utc in data frame does not correspond to a data item. Therefore it is not written to the database.\n",
      "2019-10-01T16:25:36.728 INFO iotfunctions.pipeline._get_active_cols_properties The column TestData in data frame does not correspond to a data item. Therefore it is not written to the database.\n",
      "2019-10-01T16:25:36.729 INFO iotfunctions.pipeline._get_active_cols_properties The column _timestamp in data frame does not correspond to a data item. Therefore it is not written to the database.\n",
      "2019-10-01T16:25:36.730 INFO iotfunctions.pipeline.execute The following data items will be written to the database: \n",
      "2019-10-01T16:25:36.730 DEBUG iotfunctions.pipeline._get_table_properties Mapping between index name and index position: id -> 0, evt_timestamp -> 1\n",
      "2019-10-01T16:25:36.731 INFO iotfunctions.pipeline.execute The data items will be written into the following tables: \n",
      "2019-10-01T16:25:36.732 WARNING iotfunctions.pipeline.execute There are no data items that have to be written to the database.\n",
      "2019-10-01T16:25:36.733 DEBUG iotfunctions.pipeline.exec_stage_method No method get_column_map on markus_testdata_input_level returning default None. 'SqlAlchemyDataWriter' object has no attribute 'get_column_map'\n",
      "2019-10-01T16:25:36.734 INFO iotfunctions.pipeline.update_last_entry Trace message:  Completed stage.\n",
      "2019-10-01T16:25:36.734 INFO iotfunctions.pipeline.update_last_entry Trace payload: {'produces_output_items': False, 'output_items': None, 'discard_prior_data': False, 'new_data_items_info': 'Function is configured not to produce any new data items  during execution', 'can_proceed': True, 'updated': datetime.datetime(2019, 10, 1, 14, 25, 36, 734158), 'cumulative_usage': 180}\n",
      "2019-10-01T16:25:36.738 WARNING iotfunctions.pipeline.write Error aligning input data to granularity daily\n",
      "2019-10-01T16:25:36.739 DEBUG iotfunctions.pipeline.write Executing stage auto_aggregate.\n",
      "2019-10-01T16:25:36.749 INFO iotfunctions.pipeline.execute Completed aggregation: daily\n",
      "2019-10-01T16:25:36.751 DEBUG iotfunctions.pipeline.exec_stage_method No method get_column_map on auto_aggregate returning default None. 'DataAggregator' object has no attribute 'get_column_map'\n",
      "2019-10-01T16:25:36.752 INFO iotfunctions.pipeline.update_last_entry Trace message:  Completed stage.\n",
      "2019-10-01T16:25:36.754 INFO iotfunctions.pipeline.update_last_entry Trace payload: {'produces_output_items': True, 'output_items': ['TestData_max'], 'discard_prior_data': True, 'merge_result': 'replaced prior data', 'index': [], 'can_proceed': True, 'updated': datetime.datetime(2019, 10, 1, 14, 25, 36, 752633), 'cumulative_usage': 180}\n",
      "2019-10-01T16:25:36.755 DEBUG iotfunctions.pipeline.write Executing stage markus_testdata_daily.\n",
      "2019-10-01T16:25:36.756 DEBUG iotfunctions.pipeline.execute Data items will be written to database for interval (None, 2019-10-01 14:25:34.947989)\n",
      "2019-10-01T16:25:36.757 INFO iotfunctions.pipeline.execute The following data items will be written to the database: TestData_max (dm_markus_testdata_daily, NUMBER)\n",
      "2019-10-01T16:25:36.758 DEBUG iotfunctions.pipeline._get_table_properties Mapping between index name and index position: deviceid -> 0, evt_timestamp -> 1\n",
      "2019-10-01T16:25:38.669 DEBUG iotfunctions.pipeline._get_table_properties For table dm_markus_testdata_daily: delete statement: DELETE FROM dm_markus_testdata_daily, insert statement: INSERT INTO dm_markus_testdata_daily (entity_id, key, value_n, value_b, value_s, value_t, timestamp, last_update) VALUES (:entity_id, :key, :value_n, :value_b, :value_s, :value_t, :timestamp, :last_update)\n",
      "2019-10-01T16:25:38.671 DEBUG iotfunctions.pipeline._get_table_properties For table dm_markus_testdata_daily: Mapping between column name and dataframe index position: ('entity_id', 0), ('TIMESTAMP', 1)\n",
      "2019-10-01T16:25:38.672 INFO iotfunctions.pipeline.execute The data items will be written into the following tables: dm_markus_testdata_daily\n",
      "2019-10-01T16:25:38.673 DEBUG iotfunctions.pipeline._delete_old_data Deleting old data items from table dm_markus_testdata_daily for time range [None, 2019-10-01 14:25:34.947989]\n",
      "2019-10-01T16:25:39.109 INFO iotfunctions.pipeline._delete_old_data 0 data items have been deleted from table dm_markus_testdata_daily. Elapsed time in sec: 0.434\n",
      "Persist row: ({'KEY': 'TestData_max', 'entity_id': '73004', 'TIMESTAMP': Timestamp('2019-10-01 00:00:00', freq='D'), 'value_b': None, 'value_n': 0.953396136664403, 'value_s': None, 'value_t': None})\n",
      "Persist row: ({'KEY': 'TestData_max', 'entity_id': '73000', 'TIMESTAMP': Timestamp('2019-10-01 00:00:00', freq='D'), 'value_b': None, 'value_n': 1.52094274992196, 'value_s': None, 'value_t': None})\n",
      "Persist row: ({'KEY': 'TestData_max', 'entity_id': '73002', 'TIMESTAMP': Timestamp('2019-10-01 00:00:00', freq='D'), 'value_b': None, 'value_n': 2.12616774515587, 'value_s': None, 'value_t': None})\n",
      "Persist row: ({'KEY': 'TestData_max', 'entity_id': '73003', 'TIMESTAMP': Timestamp('2019-10-01 00:00:00', freq='D'), 'value_b': None, 'value_n': 1.39164198020907, 'value_s': None, 'value_t': None})\n",
      "Persist row: ({'KEY': 'TestData_max', 'entity_id': '73001', 'TIMESTAMP': Timestamp('2019-10-01 00:00:00', freq='D'), 'value_b': None, 'value_n': 2.1039020307689, 'value_s': None, 'value_t': None})\n",
      "2019-10-01T16:25:40.130 INFO iotfunctions.pipeline._persist_data Number of data item values persisted so far: 5 (dm_markus_testdata_daily)\n",
      "2019-10-01T16:25:40.133 INFO iotfunctions.pipeline._persist_data Total number of persisted data item values: 5, Elapsed time in sec: 1.023, SqlAlchemy time in sec: 1.018\n",
      "2019-10-01T16:25:40.135 DEBUG iotfunctions.pipeline.exec_stage_method No method get_column_map on markus_testdata_daily returning default None. 'SqlAlchemyDataWriter' object has no attribute 'get_column_map'\n",
      "[]\n",
      "2019-10-01T16:25:40.137 INFO iotfunctions.pipeline.update_last_entry Trace message:  Completed stage.\n",
      "2019-10-01T16:25:40.138 INFO iotfunctions.pipeline.update_last_entry Trace payload: {'produces_output_items': False, 'output_items': None, 'discard_prior_data': False, 'new_data_items_info': 'Function is configured not to produce any new data items  during execution', 'can_proceed': True, 'updated': datetime.datetime(2019, 10, 1, 14, 25, 40, 136772), 'cumulative_usage': 180}\n",
      "2019-10-01T16:25:40.139 INFO iotfunctions.pipeline.write Execution complete\n",
      "2019-10-01T16:25:40.142 DEBUG urllib3.connectionpool._new_conn Starting new HTTPS connection (1): s3-api.us-geo.objectstorage.softlayer.net\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markus/.local/lib/python3.7/site-packages/urllib3/connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-01T16:25:40.941 DEBUG urllib3.connectionpool._make_request https://s3-api.us-geo.objectstorage.softlayer.net:443 \"PUT /analytics-runtime-analyticsservicedev-799d2008b460/AnalyticsServiceDev/markus_testdata/20191001/markus_testdata_trace_142534 HTTP/1.1\" 200 0\n",
      "2019-10-01T16:25:40.942 DEBUG iotfunctions.pipeline.save Saved trace to cos AnalyticsServiceDev/markus_testdata/20191001/markus_testdata_trace_142534\n",
      "2019-10-01T16:25:40.945 DEBUG iotfunctions.pipeline.save wrote trace to file auto_trace_markus_testdata_20191001142534.json\n",
      "2019-10-01T16:25:41.373 DEBUG iotfunctions.pipeline.update Updated job log (markus_testdata,5min): 2019-10-01 14:25:34.947989\n",
      "2019-10-01T16:25:41.374 DEBUG iotfunctions.pipeline.get_next_future_execution Next scheduled execution date is 2019-10-01 14:30:34.947989\n",
      "2019-10-01T16:25:41.375 DEBUG iotfunctions.pipeline.execute Ending job normally as there are no scheduled executions  due before execution end time\n",
      "2019-10-01T16:25:41.388 DEBUG iotfunctions.pipeline.run_auto_save auto_trace_markus_testdata_20191001142534 autosave thread has stopped\n",
      "2019-10-01T16:25:41.390 DEBUG iotfunctions.pipeline.stop Stopping autosave on trace auto_trace_markus_testdata_20191001142534\n"
     ]
    }
   ],
   "source": [
    "# dm_markus_testdate MUST exist, so run the following sql statment in DBeaver\n",
    "\n",
    "#  for db2\n",
    "#CREATE TABLE BLUADMIN.DM_MARKUS_TESTDATA_DAILY (\n",
    "#  entity_id varchar(255),\n",
    "#  key varchar(255),\n",
    "#  value_n double,\n",
    "#  value_b boolean,\n",
    "#  value_s varchar(255),\n",
    "#  value_t timestamp,\n",
    "#  timestamp timestamp,\n",
    "#  last_update timestamp\n",
    "# );\n",
    "\n",
    "#   for postgres\n",
    "#CREATE TABLE public.DM_MARKUS_TESTDATA_DAILY (\n",
    "#  entity_id varchar(255),\n",
    "#  key varchar(255),\n",
    "#  value_n double precision,\n",
    "#  value_b boolean,\n",
    "#  value_s varchar(255),\n",
    "#  value_t timestamp,\n",
    "#  timestamp timestamp,\n",
    "#  last_update timestamp\n",
    "# );\n",
    "\n",
    "from iotfunctions.metadata import Granularity\n",
    "from iotfunctions.pipeline import AggregateItems\n",
    "daily = Granularity(\n",
    "    name = 'daily',\n",
    "    freq = '1D',                 # pandas frequency string\n",
    "    timestamp= 'evt_timestamp',      # build time aggregations using this datetime col\n",
    "    entity_id = 'deviceid',            # aggregate by id\n",
    "    dimensions = None,\n",
    "    entity_name = None\n",
    ")\n",
    "\n",
    "#myAgg = bif.AggregateWithExpression(['TestData'],'x.max()','TestMax')\n",
    "myAgg = AggregateItems(['TestData'], 'max')\n",
    "myAgg.granularity = daily\n",
    "\n",
    "et2._functions = [myAgg]\n",
    "et2.grains = [daily]\n",
    "#et2._granularities_dict['daily'] = daily\n",
    "\n",
    "#jobsettings = {'writer_name' : SqlAlchemyDataWriter, '_db_schema': 'BLUADMIN', 'save_trace_to_file' : True}\n",
    "jobsettings = {'writer_name' : SqlAlchemyDataWriter, '_db_schema': 'public', 'save_trace_to_file' : True}\n",
    "job = pp.JobController(et2, **jobsettings)\n",
    "#job.data_writer = DataWriterFile\n",
    "job.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-01T16:25:51.201 DEBUG iotfunctions.metadata.index_df Indexed dataframe on id, evt_timestamp\n",
      "                                 deviceid       devicetype  \\\n",
      "id    evt_timestamp                                          \n",
      "73004 2019-10-01 13:06:25.341693    73004  markus_testdata   \n",
      "73000 2019-10-01 13:07:25.341693    73000  markus_testdata   \n",
      "      2019-10-01 13:08:25.341693    73000  markus_testdata   \n",
      "73002 2019-10-01 13:09:25.341693    73002  markus_testdata   \n",
      "73004 2019-10-01 13:10:25.341693    73004  markus_testdata   \n",
      "73000 2019-10-01 13:11:25.341693    73000  markus_testdata   \n",
      "73003 2019-10-01 13:12:27.737110    73003  markus_testdata   \n",
      "73004 2019-10-01 13:13:27.737110    73004  markus_testdata   \n",
      "73003 2019-10-01 13:14:27.737110    73003  markus_testdata   \n",
      "      2019-10-01 13:15:27.737110    73003  markus_testdata   \n",
      "73000 2019-10-01 13:16:27.737110    73000  markus_testdata   \n",
      "      2019-10-01 13:17:27.737110    73000  markus_testdata   \n",
      "      2019-10-01 14:03:59.994715    73000  markus_testdata   \n",
      "73001 2019-10-01 14:04:59.994715    73001  markus_testdata   \n",
      "      2019-10-01 14:05:59.994715    73001  markus_testdata   \n",
      "      2019-10-01 14:06:59.994715    73001  markus_testdata   \n",
      "73002 2019-10-01 14:07:59.994715    73002  markus_testdata   \n",
      "73001 2019-10-01 14:08:59.994715    73001  markus_testdata   \n",
      "      2019-10-01 14:07:29.501986    73001  markus_testdata   \n",
      "      2019-10-01 14:08:29.501986    73001  markus_testdata   \n",
      "73002 2019-10-01 14:09:29.501986    73002  markus_testdata   \n",
      "73003 2019-10-01 14:10:29.501986    73003  markus_testdata   \n",
      "73000 2019-10-01 14:11:29.501986    73000  markus_testdata   \n",
      "73003 2019-10-01 14:12:29.501986    73003  markus_testdata   \n",
      "73002 2019-10-01 14:11:56.729650    73002  markus_testdata   \n",
      "73001 2019-10-01 14:12:56.729650    73001  markus_testdata   \n",
      "73004 2019-10-01 14:13:56.729650    73004  markus_testdata   \n",
      "73002 2019-10-01 14:14:56.729650    73002  markus_testdata   \n",
      "73004 2019-10-01 14:15:56.729650    73004  markus_testdata   \n",
      "      2019-10-01 14:16:56.729650    73004  markus_testdata   \n",
      "73003 2019-10-01 14:13:53.168118    73003  markus_testdata   \n",
      "73004 2019-10-01 14:14:53.168118    73004  markus_testdata   \n",
      "73003 2019-10-01 14:15:53.168118    73003  markus_testdata   \n",
      "73004 2019-10-01 14:16:53.168118    73004  markus_testdata   \n",
      "      2019-10-01 14:17:53.168118    73004  markus_testdata   \n",
      "73002 2019-10-01 14:18:53.168118    73002  markus_testdata   \n",
      "\n",
      "                                 logicalinterface_id eventtype format  \\\n",
      "id    evt_timestamp                                                     \n",
      "73004 2019-10-01 13:06:25.341693                            en          \n",
      "73000 2019-10-01 13:07:25.341693                            en          \n",
      "      2019-10-01 13:08:25.341693                            yt          \n",
      "73002 2019-10-01 13:09:25.341693                            tt          \n",
      "73004 2019-10-01 13:10:25.341693                            ne          \n",
      "73000 2019-10-01 13:11:25.341693                            tt          \n",
      "73003 2019-10-01 13:12:27.737110                            ep          \n",
      "73004 2019-10-01 13:13:27.737110                            te          \n",
      "73003 2019-10-01 13:14:27.737110                            en          \n",
      "      2019-10-01 13:15:27.737110                            vt          \n",
      "73000 2019-10-01 13:16:27.737110                            et          \n",
      "      2019-10-01 13:17:27.737110                            ty          \n",
      "      2019-10-01 14:03:59.994715                            ey          \n",
      "73001 2019-10-01 14:04:59.994715                            et          \n",
      "      2019-10-01 14:05:59.994715                            et          \n",
      "      2019-10-01 14:06:59.994715                            tt          \n",
      "73002 2019-10-01 14:07:59.994715                            ye          \n",
      "73001 2019-10-01 14:08:59.994715                            ey          \n",
      "      2019-10-01 14:07:29.501986                            en          \n",
      "      2019-10-01 14:08:29.501986                            en          \n",
      "73002 2019-10-01 14:09:29.501986                            et          \n",
      "73003 2019-10-01 14:10:29.501986                            tn          \n",
      "73000 2019-10-01 14:11:29.501986                            et          \n",
      "73003 2019-10-01 14:12:29.501986                            ye          \n",
      "73002 2019-10-01 14:11:56.729650                            ny          \n",
      "73001 2019-10-01 14:12:56.729650                            ne          \n",
      "73004 2019-10-01 14:13:56.729650                            ee          \n",
      "73002 2019-10-01 14:14:56.729650                            tt          \n",
      "73004 2019-10-01 14:15:56.729650                            ny          \n",
      "      2019-10-01 14:16:56.729650                            pt          \n",
      "73003 2019-10-01 14:13:53.168118                            te          \n",
      "73004 2019-10-01 14:14:53.168118                            en          \n",
      "73003 2019-10-01 14:15:53.168118                            en          \n",
      "73004 2019-10-01 14:16:53.168118                            ee          \n",
      "      2019-10-01 14:17:53.168118                            nv          \n",
      "73002 2019-10-01 14:18:53.168118                            pe          \n",
      "\n",
      "                                 updated_utc  TestData  \\\n",
      "id    evt_timestamp                                      \n",
      "73004 2019-10-01 13:06:25.341693        None -1.012887   \n",
      "73000 2019-10-01 13:07:25.341693        None  0.640831   \n",
      "      2019-10-01 13:08:25.341693        None  0.657694   \n",
      "73002 2019-10-01 13:09:25.341693        None -2.390681   \n",
      "73004 2019-10-01 13:10:25.341693        None -0.234181   \n",
      "73000 2019-10-01 13:11:25.341693        None  0.952477   \n",
      "73003 2019-10-01 13:12:27.737110        None -0.107018   \n",
      "73004 2019-10-01 13:13:27.737110        None -0.203514   \n",
      "73003 2019-10-01 13:14:27.737110        None  0.720092   \n",
      "      2019-10-01 13:15:27.737110        None -1.720990   \n",
      "73000 2019-10-01 13:16:27.737110        None  1.520943   \n",
      "      2019-10-01 13:17:27.737110        None  0.097358   \n",
      "      2019-10-01 14:03:59.994715        None  0.521085   \n",
      "73001 2019-10-01 14:04:59.994715        None  1.059213   \n",
      "      2019-10-01 14:05:59.994715        None  0.064902   \n",
      "      2019-10-01 14:06:59.994715        None  0.762488   \n",
      "73002 2019-10-01 14:07:59.994715        None -0.715103   \n",
      "73001 2019-10-01 14:08:59.994715        None  2.103902   \n",
      "      2019-10-01 14:07:29.501986        None  0.124766   \n",
      "      2019-10-01 14:08:29.501986        None  0.014392   \n",
      "73002 2019-10-01 14:09:29.501986        None  0.359201   \n",
      "73003 2019-10-01 14:10:29.501986        None  1.391642   \n",
      "73000 2019-10-01 14:11:29.501986        None  0.431859   \n",
      "73003 2019-10-01 14:12:29.501986        None  0.889539   \n",
      "73002 2019-10-01 14:11:56.729650        None -0.150771   \n",
      "73001 2019-10-01 14:12:56.729650        None  1.145375   \n",
      "73004 2019-10-01 14:13:56.729650        None  0.144240   \n",
      "73002 2019-10-01 14:14:56.729650        None  2.126168   \n",
      "73004 2019-10-01 14:15:56.729650        None -0.211232   \n",
      "      2019-10-01 14:16:56.729650        None  0.753428   \n",
      "73003 2019-10-01 14:13:53.168118        None  0.392042   \n",
      "73004 2019-10-01 14:14:53.168118        None -0.288730   \n",
      "73003 2019-10-01 14:15:53.168118        None  1.062992   \n",
      "73004 2019-10-01 14:16:53.168118        None  0.635863   \n",
      "      2019-10-01 14:17:53.168118        None  0.953396   \n",
      "73002 2019-10-01 14:18:53.168118        None -0.189876   \n",
      "\n",
      "                                                 _timestamp  \n",
      "id    evt_timestamp                                          \n",
      "73004 2019-10-01 13:06:25.341693 2019-10-01 13:06:25.341693  \n",
      "73000 2019-10-01 13:07:25.341693 2019-10-01 13:07:25.341693  \n",
      "      2019-10-01 13:08:25.341693 2019-10-01 13:08:25.341693  \n",
      "73002 2019-10-01 13:09:25.341693 2019-10-01 13:09:25.341693  \n",
      "73004 2019-10-01 13:10:25.341693 2019-10-01 13:10:25.341693  \n",
      "73000 2019-10-01 13:11:25.341693 2019-10-01 13:11:25.341693  \n",
      "73003 2019-10-01 13:12:27.737110 2019-10-01 13:12:27.737110  \n",
      "73004 2019-10-01 13:13:27.737110 2019-10-01 13:13:27.737110  \n",
      "73003 2019-10-01 13:14:27.737110 2019-10-01 13:14:27.737110  \n",
      "      2019-10-01 13:15:27.737110 2019-10-01 13:15:27.737110  \n",
      "73000 2019-10-01 13:16:27.737110 2019-10-01 13:16:27.737110  \n",
      "      2019-10-01 13:17:27.737110 2019-10-01 13:17:27.737110  \n",
      "      2019-10-01 14:03:59.994715 2019-10-01 14:03:59.994715  \n",
      "73001 2019-10-01 14:04:59.994715 2019-10-01 14:04:59.994715  \n",
      "      2019-10-01 14:05:59.994715 2019-10-01 14:05:59.994715  \n",
      "      2019-10-01 14:06:59.994715 2019-10-01 14:06:59.994715  \n",
      "73002 2019-10-01 14:07:59.994715 2019-10-01 14:07:59.994715  \n",
      "73001 2019-10-01 14:08:59.994715 2019-10-01 14:08:59.994715  \n",
      "      2019-10-01 14:07:29.501986 2019-10-01 14:07:29.501986  \n",
      "      2019-10-01 14:08:29.501986 2019-10-01 14:08:29.501986  \n",
      "73002 2019-10-01 14:09:29.501986 2019-10-01 14:09:29.501986  \n",
      "73003 2019-10-01 14:10:29.501986 2019-10-01 14:10:29.501986  \n",
      "73000 2019-10-01 14:11:29.501986 2019-10-01 14:11:29.501986  \n",
      "73003 2019-10-01 14:12:29.501986 2019-10-01 14:12:29.501986  \n",
      "73002 2019-10-01 14:11:56.729650 2019-10-01 14:11:56.729650  \n",
      "73001 2019-10-01 14:12:56.729650 2019-10-01 14:12:56.729650  \n",
      "73004 2019-10-01 14:13:56.729650 2019-10-01 14:13:56.729650  \n",
      "73002 2019-10-01 14:14:56.729650 2019-10-01 14:14:56.729650  \n",
      "73004 2019-10-01 14:15:56.729650 2019-10-01 14:15:56.729650  \n",
      "      2019-10-01 14:16:56.729650 2019-10-01 14:16:56.729650  \n",
      "73003 2019-10-01 14:13:53.168118 2019-10-01 14:13:53.168118  \n",
      "73004 2019-10-01 14:14:53.168118 2019-10-01 14:14:53.168118  \n",
      "73003 2019-10-01 14:15:53.168118 2019-10-01 14:15:53.168118  \n",
      "73004 2019-10-01 14:16:53.168118 2019-10-01 14:16:53.168118  \n",
      "      2019-10-01 14:17:53.168118 2019-10-01 14:17:53.168118  \n",
      "73002 2019-10-01 14:18:53.168118 2019-10-01 14:18:53.168118  \n"
     ]
    }
   ],
   "source": [
    "print (et2.get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real life data\n",
    "\n",
    "import logging\n",
    "import threading\n",
    "import itertools\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import seaborn as seabornInstance\n",
    "from sqlalchemy import Column, Integer, String, Float, DateTime, Boolean, func\n",
    "from iotfunctions import base\n",
    "from iotfunctions import bif\n",
    "from iotfunctions import entity\n",
    "from iotfunctions import metadata\n",
    "from iotfunctions.metadata import EntityType\n",
    "from iotfunctions.db import Database\n",
    "from iotfunctions.enginelog import EngineLogging\n",
    "from iotfunctions import estimator\n",
    "from iotfunctions.ui import (UISingle, UIMultiItem, UIFunctionOutSingle,\n",
    "                 UISingleItem, UIFunctionOutMulti, UIMulti, UIExpression,\n",
    "                 UIText, UIStatusFlag, UIParameters)\n",
    "from mmfunctions.anomaly import (SaliencybasedGeneralizedAnomalyScore, SpectralAnomalyScore,\n",
    "                 FFTbasedGeneralizedAnomalyScore, KMeansAnomalyScore)\n",
    "import datetime as dt\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "import scipy as sp\n",
    "import scipy.fftpack\n",
    "import skimage as ski  \n",
    "from skimage import util as skiutil # for nifty windowing\n",
    "import pyod as pyod\n",
    "from pyod.utils.data import generate_data\n",
    "from pyod.utils.data import evaluate_print\n",
    "from pyod.utils.example import visualize\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.iforest import IForest\n",
    "%matplotlib inline\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "EngineLogging.configure_console_logging(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting to make life easier\n",
    "Temperature='Temperature'\n",
    "kmeans='TemperatureKmeansScore'\n",
    "fft='TemperatureFFTScore'\n",
    "spectral='TemperatureSpectralScore'\n",
    "sal='SaliencyAnomalyScore'\n",
    "gen='TemperatureGeneralizedScore'\n",
    "kmeansA='kmeansAnomaly'\n",
    "kmeansB='kmeansAnomalyB'\n",
    "spectralA='spectralAnomaly'\n",
    "fftA='fftAnomaly'\n",
    "salA='salAnomaly'\n",
    "genA='genAnomaly'\n",
    "\n",
    "kmeans_break=1.3\n",
    "spectral_break = 2.8\n",
    "fft_break = 100\n",
    "sal_break = 100\n",
    "gen_break = 30000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### What will be shown\n",
    "\n",
    "General approach is straightforward\n",
    "* read raw data in\n",
    "* transform it so that it is compatible to the Monitoring pipeline\n",
    "* add yet another anomaly detector based on computer vision technology. The point here is to show how to run pipeline anomaly functions 'locally', an important concept for automated testing.\n",
    "* simplify the dataframe - we have only one entity, no need for an entity index\n",
    "* render input data and anomaly scores properly scaled\n",
    "\n",
    "<br>\n",
    "\n",
    "We start with Microsoft's anomaly test data found here\n",
    "https://github.com/microsoft/anomalydetector/blob/master/samples/sample.csv\n",
    "\n",
    "and then proceed to applying anomaly detection to real life pump data\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "#### Current inventory of anomaly detectors by type\n",
    "\n",
    "This is the list of functions to apply\n",
    "\n",
    "\n",
    "| Detector | ML Type | Type         | How does it work |\n",
    "| ------- | ------------ | ------- | ---------------- |\n",
    "| KMeans | Unsupervised | Proximity | Clusters data points in centroid buckets, small buckets are outliers, score is distance to closest other bucket |\n",
    "| Generalized | Unsupervised | Linear Model | Covariance matrix over data point vectors serves to measure multi-dimensional deviation |\n",
    "| FFT | Unsupervised | Linear Model | Run FFT before applying Generalized |\n",
    "| Spectral | Unsupervised | Linear Model | Compute signal energy to reduce dimensions |\n",
    "| Saliency | Unsupervised | Linear Model | Apply saliency transform (from computer vision |\n",
    "| SimpleAnomaly | **Supervised** | Ensemble | Run Gradient boosting on training data, anomaly if prediction deviates from actual data |\n",
    "| --- | **Supervised** | LSTM | Train a stacked LSTM, anomaly if prediction deviates from actual data |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run on the good pump first \n",
    "# Get stuff in\n",
    "df_i = pd.read_csv('./AzureAnomalysample.csv', index_col=False, parse_dates=['timestamp'])\n",
    "\n",
    "df_i['entity']='MyRoom'\n",
    "df_i['Temperature']=df_i['value'] + 20\n",
    "df_i = df_i.drop(columns=['value'])\n",
    "\n",
    "# and sort it by timestamp\n",
    "df_i = df_i.sort_values(by='timestamp')\n",
    "df_i = df_i.set_index(['entity','timestamp']).dropna()\n",
    "\n",
    "df_i.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now run the anomaly functions as if they were executed in a pipeline\n",
    "\n",
    "spsi = SpectralAnomalyScore(Temperature, 12, spectral)\n",
    "et = spsi._build_entity_type(columns = [Column(Temperature,Float())])\n",
    "spsi._entity_type = et\n",
    "df_i = spsi.execute(df=df_i)\n",
    "\n",
    "sali = SaliencybasedGeneralizedAnomalyScore(Temperature, 12, sal)\n",
    "et = sali._build_entity_type(columns = [Column(Temperature,Float())])\n",
    "sali._entity_type = et\n",
    "df_i = sali.execute(df=df_i)\n",
    "\n",
    "ffti = FFTbasedGeneralizedAnomalyScore(Temperature, 12, fft)\n",
    "et = ffti._build_entity_type(columns = [Column(Temperature,Float())])\n",
    "ffti._entity_type = et\n",
    "df_i = ffti.execute(df=df_i)\n",
    "\n",
    "kmi = KMeansAnomalyScore(Temperature, 12, kmeans)\n",
    "et = kmi._build_entity_type(columns = [Column(Temperature,Float())])\n",
    "kmi._entity_type = et\n",
    "df_i = kmi.execute(df=df_i)\n",
    "\n",
    "df_i.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplify our pandas dataframe to prepare input for plotting\n",
    "EngineLogging.configure_console_logging(logging.INFO)\n",
    "\n",
    "df_inputm2 = df_i.loc[['MyRoom']]\n",
    "df_inputm2.reset_index(level=[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_inputm2[spectral].values[df_inputm2[spectral] > 0.001] = 0.001\n",
    "# df_inputm2[fft].values[df_inputm2[fft] < -1] = -1\n",
    "df_inputm2[kmeansA] = df_inputm2[kmeans]\n",
    "df_inputm2[kmeansA].values[df_inputm2[kmeansA] < kmeans_break] = np.nan\n",
    "df_inputm2[kmeansA].values[df_inputm2[kmeansA] > kmeans_break] = kmeans_break\n",
    "df_inputm2[kmeansB] = df_inputm2[kmeans]\n",
    "df_inputm2[kmeansB].values[df_inputm2[kmeansB] >= kmeans_break] = 4\n",
    "df_inputm2[kmeansB].values[df_inputm2[kmeansB] < kmeans_break] = 3\n",
    "\n",
    "# Scale spectral and saliency \n",
    "# df_inputm2[spectral].values[df_inputm2[spectral] >= spectral_break] = -spectral_break\n",
    "# df_inputm2[sal].values[df_inputm2[sal] > sal_break] = sal_break\n",
    "\n",
    "\n",
    "\n",
    "df_inputm2[fftA] = df_inputm2[fft]\n",
    "df_inputm2[fftA].values[df_inputm2[fftA] < fft_break] = np.nan\n",
    "df_inputm2[fftA].values[df_inputm2[fftA] > fft_break] = fft_break\n",
    "df_inputm2[spectralA] = df_inputm2[spectral]\n",
    "df_inputm2[spectralA].values[df_inputm2[spectralA] < spectral_break] = np.nan\n",
    "df_inputm2[spectralA].values[df_inputm2[spectralA] > spectral_break] = spectral_break\n",
    "df_inputm2[salA] = df_inputm2[sal]\n",
    "df_inputm2[salA].values[df_inputm2[salA] < sal_break] = np.nan\n",
    "df_inputm2[salA].values[df_inputm2[salA] > sal_break] = sal_break\n",
    "#df_inputm2[genA] = df_inputm2[gen]\n",
    "#df_inputm2[genA].values[df_inputm2[genA] < gen_break] = np.nan\n",
    "#df_inputm2[genA].values[df_inputm2[genA] > gen_break] = gen_break\n",
    "\n",
    "plots = 5\n",
    "\n",
    "fig, ax = plt.subplots(plots, 1, figsize=(16,24))\n",
    "cnt = 0\n",
    "ax[cnt].plot(df_inputm2.index, df_inputm2[Temperature]-20,linewidth=1,color='black',label=Temperature)\n",
    "ax[cnt].legend(bbox_to_anchor=(1.1, 1.05))\n",
    "ax[cnt].set_ylabel('Input Temperature - 20',fontsize=14,weight=\"bold\")\n",
    "cnt = 1\n",
    "#ax[cnt].plot(df_inputm2.index, df_inputm2[Temperature]-20,linewidth=1,color='black',label=Input)\n",
    "#ax[cnt].plot(df_inputm2.index, df_inputm2[kmeans], linewidth=2, color='magenta',label=kmeans)\n",
    "#ax[cnt].plot(df_inputm2.index, df_inputm2[fft]/fft_break, linewidth=2,color='darkgreen',label=fft)\n",
    "#ax[cnt].plot(df_inputm2.index, -df_inputm2[spectral]/spectral_break, linewidth=2,color='dodgerblue', label=spectral)\n",
    "#ax[cnt].plot(df_inputm2.index, df_inputm2[sal]/sal_break, linewidth=2,color='chartreuse',label=sal)\n",
    "#ax[cnt].legend(bbox_to_anchor=(1.1, 1.05))\n",
    "#ax[cnt].set_ylabel('ALL',fontsize=14,weight=\"bold\")\n",
    "cnt = 1\n",
    "ax[cnt].plot(df_inputm2.index, df_inputm2[Temperature]-20,linewidth=1,color='black',label=Temperature)\n",
    "ax[cnt].plot(df_inputm2.index, df_inputm2[kmeans], linewidth=2, color='magenta',label=kmeans)\n",
    "ax[cnt].plot(df_inputm2.index, df_inputm2[kmeansA], linewidth=10, color='red') #,label=kmeansA)\n",
    "ax[cnt].legend(bbox_to_anchor=(1.1, 1.05))\n",
    "ax[cnt].set_ylabel('KMeans \\n detects chanages in \"steepness\"',fontsize=13)\n",
    "cnt = 2\n",
    "ax[cnt].plot(df_inputm2.index, df_inputm2[Temperature]-20,linewidth=1,color='black',label=Temperature)\n",
    "ax[cnt].plot(df_inputm2.index, df_inputm2[fft]/fft_break, linewidth=2,color='darkgreen',label=fft)\n",
    "ax[cnt].plot(df_inputm2.index, df_inputm2[fftA]/fft_break, linewidth=10, color='red') #,label=kmeansA)\n",
    "ax[cnt].legend(bbox_to_anchor=(1.1, 1.05))\n",
    "ax[cnt].set_ylabel('FFT \\n detects frequency changes', fontsize=13)\n",
    "cnt = 3\n",
    "ax[cnt].plot(df_inputm2.index, df_inputm2[Temperature]-20,linewidth=1,color='black',label=Temperature)\n",
    "ax[cnt].plot(df_inputm2.index, df_inputm2[spectral]/spectral_break, linewidth=2,color='dodgerblue', label=spectral)\n",
    "ax[cnt].plot(df_inputm2.index, df_inputm2[spectralA]/spectral_break, linewidth=10, color='red') #,label=kmeansA)\n",
    "ax[cnt].legend(bbox_to_anchor=(1.1, 1.05))\n",
    "ax[cnt].set_ylabel('Spectral \\n like FFT for less \"CPU\"\\n less sensitive', fontsize=13)\n",
    "cnt = 4\n",
    "ax[cnt].plot(df_inputm2.index, df_inputm2[Temperature]-20,linewidth=1,color='black',label=Temperature)\n",
    "ax[cnt].plot(df_inputm2.index, df_inputm2[sal]/sal_break, linewidth=2,color='chartreuse', label=sal)\n",
    "ax[cnt].plot(df_inputm2.index, df_inputm2[salA]/sal_break, linewidth=10, color='red') #,label=kmeansA)\n",
    "ax[cnt].legend(bbox_to_anchor=(1.1, 1.05))\n",
    "ax[cnt].set_ylabel('Saliency \\n like FFT, part of Azure\\'s approach', fontsize=13)\n",
    "\n",
    "for i in range(plots):\n",
    "    ax[i].grid(True, color='white')\n",
    "    ax[i].set_facecolor('lightgrey')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "Clear **winners** are \n",
    "* **KMeans** and \n",
    "* **FFT**.\n",
    "\n",
    "Spectral is way too sensitive while Saliency \n",
    "doesn't detect the negative peak at 10/10 midnight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need a helper function to convert array columns to something easier\n",
    "from scipy import linalg\n",
    "def l2norm(df, tcol, col1, col2 = None, col3 = None):\n",
    "    l2vib = []\n",
    "    for index, row in df.iterrows():\n",
    "        l2vib_element = linalg.norm(np.fromstring(row[col1].replace('[',' ').replace(']',''), sep = ','))**2\n",
    "        if col2 is not None:\n",
    "            l2vib_element = l2vib_element + \\\n",
    "                            linalg.norm(np.fromstring(row[col2].replace('[',' ').replace(']',''), sep = ','))**2\n",
    "        if col3 is not None:\n",
    "            l2vib_element = l2vib_element + \\\n",
    "                            linalg.norm(np.fromstring(row[col3].replace('[',' ').replace(']',''), sep = ','))**2\n",
    "        l2vib.append(l2vib_element**(1/2))\n",
    "    df[tcol] = np.asarray(l2vib)\n",
    "    \n",
    "\n",
    "def unrollAccel(df):\n",
    "    l0,l1,l2,l3,l4=[],[],[],[],[]\n",
    "    for i in df['ACCEL_POWER'].values:\n",
    "        l0.append(eval(eval(i)[0]))\n",
    "        l1.append(eval(eval(i)[1]))\n",
    "        l2.append(eval(eval(i)[2]))\n",
    "        l3.append(eval(eval(i)[3]))\n",
    "        l4.append(eval(eval(i)[4]))\n",
    "    df['accel_power_0'] = np.asarray(l0)\n",
    "    df['accel_power_1'] = np.asarray(l1)\n",
    "    df['accel_power_2'] = np.asarray(l2)\n",
    "    df['accel_power_3'] = np.asarray(l3)\n",
    "    df['accel_power_4'] = np.asarray(l4)\n",
    "    \n",
    "listAttr = ['timestamp','entity','vibrations','rms','accel_speed','accel_power_0','accel_power_1',\n",
    "            'accel_power_2','accel_power_3','accel_power_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now we proceed to customer data - GOOD CASE\n",
    "\n",
    "# Get stuff in\n",
    "df_input_raw = pd.read_csv('./Armstark04714B6046D5.csv', index_col=False, parse_dates=['RCV_TIMESTAMP_UTC'])\n",
    "df_input_raw['entity']=df_input_raw['DEVICE_ID']\n",
    "df_input_raw['timestamp']=df_input_raw['RCV_TIMESTAMP_UTC']\n",
    "\n",
    "# and sort it by timestamp\n",
    "df_input_raw = df_input_raw.sort_values(by='timestamp')\n",
    "df_input_raw = df_input_raw.set_index(['entity','timestamp']).dropna()\n",
    "\n",
    "l2norm(df_input_raw, 'vibrations', 'VIBRATIONS_XAXIS', 'VIBRATIONS_YAXIS', 'VIBRATIONS_ZAXIS')\n",
    "l2norm(df_input_raw, 'rms', 'RMS_X', 'RMS_Y', 'RMS_Z')\n",
    "l2norm(df_input_raw, 'accel_speed', 'ACCEL_SPEED')\n",
    "unrollAccel(df_input_raw)\n",
    "#l2norm(df_input_raw, 'accel_power', 'ACCEL_POWER')\n",
    "\n",
    "df_input = df_input_raw.filter(listAttr, axis=1)\n",
    "df_input_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Monitoring's anomaly detector functions\n",
    "\n",
    "salii = SaliencybasedGeneralizedAnomalyScore('vibrations', 12, 'SaliencyVibrationScore')\n",
    "et = salii._build_entity_type(columns = [Column('vibrations',Float())])\n",
    "salii._entity_type = et\n",
    "df_input = salii.execute(df=df_input)\n",
    "\n",
    "\n",
    "spsii = SpectralAnomalyScore('vibrations', 12, 'SpectralVibrationScore')\n",
    "et = spsii._build_entity_type(columns = [Column('vibrations',Float())])\n",
    "spsii._entity_type = et\n",
    "df_input = spsii.execute(df=df_input)\n",
    "\n",
    "kmii = KMeansAnomalyScore('vibrations', 12, 'KMeansVibrationScore')\n",
    "et = kmii._build_entity_type(columns = [Column('vibrations',Float())])\n",
    "kmii._entity_type = et\n",
    "df_input = kmii.execute(df=df_input)\n",
    "\n",
    "fftii = FFTbasedGeneralizedAnomalyScore('vibrations', 12, 'FFTVibrationScore')\n",
    "et = fftii._build_entity_type(columns = [Column('vibrations',Float())])\n",
    "fftii._entity_type = et\n",
    "df_input = fftii.execute(df=df_input)\n",
    "\n",
    "df_input.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EngineLogging.configure_console_logging(logging.INFO)\n",
    "\n",
    "df_input2 = df_input.loc[['04714B6046D5']]\n",
    "df_input2.reset_index(level=[0], inplace=True)\n",
    "\n",
    "# redefine\n",
    "# setting to make life easier\n",
    "Temperature='vibrations'\n",
    "kmeans='KMeansVibrationScore'\n",
    "fft='FFTVibrationScore'\n",
    "spectral='SpectralVibrationScore'\n",
    "sal='SaliencyVibrationScore'\n",
    "#gen='TemperatureGeneralizedScore'\n",
    "kmeansA='kmeansAnomaly'\n",
    "kmeansB='kmeansAnomalyB'\n",
    "spectralA='spectralAnomaly'\n",
    "fftA='fftAnomaly'\n",
    "salA='salAnomaly'\n",
    "genA='genAnomaly'\n",
    "\n",
    "kmeans_break=1.3\n",
    "spectral_break = 2.8\n",
    "fft_break = 100\n",
    "sal_break = 100\n",
    "gen_break = 30000\n",
    "\n",
    "df_input2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_input2[spectral].values[df_input2[spectral] > 0.001] = 0.001\n",
    "df_input2[fft].values[df_input2[fft] < -1] = -1\n",
    "df_input2[kmeansA] = df_input2[kmeans]\n",
    "df_input2[kmeansA].values[df_input2[kmeansA] < kmeans_break] = np.nan\n",
    "df_input2[kmeansA].values[df_input2[kmeansA] > kmeans_break] = kmeans_break\n",
    "df_input2[kmeansB] = df_input2[kmeans]\n",
    "df_input2[kmeansB].values[df_input2[kmeansB] >= kmeans_break] = 4\n",
    "df_input2[kmeansB].values[df_input2[kmeansB] < kmeans_break] = 3\n",
    "\n",
    "\n",
    "\n",
    "df_input2[fftA] = df_input2[fft]\n",
    "df_input2[fftA].values[df_input2[fftA] < fft_break] = np.nan\n",
    "df_input2[fftA].values[df_input2[fftA] > fft_break] = fft_break\n",
    "df_input2[spectralA] = df_input2[spectral]\n",
    "df_input2[spectralA].values[df_input2[spectralA] < spectral_break] = np.nan\n",
    "df_input2[spectralA].values[df_input2[spectralA] > spectral_break] = spectral_break\n",
    "df_input2[salA] = df_input2[sal]\n",
    "df_input2[salA].values[df_input2[salA] < sal_break] = np.nan\n",
    "df_input2[salA].values[df_input2[salA] > sal_break] = sal_break\n",
    "#df_input2[genA] = df_input2[gen]\n",
    "#df_input2[genA].values[df_input2[genA] < gen_break] = np.nan\n",
    "#df_input2[genA].values[df_input2[genA] > gen_break] = gen_break\n",
    "\n",
    "plots = 6\n",
    "\n",
    "fig, ax = plt.subplots(plots, 1, figsize=(12,20))\n",
    "cnt = 0\n",
    "ax[cnt].plot(df_input2.index, df_input2[Temperature],linewidth=1,color='black',label=Temperature)\n",
    "ax[cnt].plot(df_input2.index, df_input2[kmeans], linewidth=2, color='magenta',label=kmeans)\n",
    "ax[cnt].plot(df_input2.index, df_input2[fft]/fft_break, linewidth=2,color='darkgreen',label=fft)\n",
    "ax[cnt].plot(df_input2.index, df_input2[spectral]/spectral_break, linewidth=2,color='dodgerblue', label=spectral)\n",
    "ax[cnt].plot(df_input2.index, df_input2[sal]/sal_break, linewidth=2,color='chartreuse',label=sal)\n",
    "#ax[0].plot(df_input2.index, df_input2[gen]/gen_break, linewidth=2,color='darkviolet',label=gen)\n",
    "ax[cnt].legend(bbox_to_anchor=(1.1, 1.05))\n",
    "ax[cnt].set_ylabel('ALL',fontsize=14,weight=\"bold\")\n",
    "cnt=1\n",
    "ax[cnt].plot(df_input2.index, df_input2[Temperature],linewidth=1,color='black',label=Temperature)\n",
    "ax[cnt].plot(df_input2.index, df_input2[kmeans], linewidth=2, color='magenta',label=kmeans)\n",
    "#ax[cnt].plot(df_input2.index, df_input2[kmeansB], linewidth=2, color='yellow') #label=kmeans)\n",
    "ax[cnt].plot(df_input2.index, df_input2[kmeansA], linewidth=10, color='red') #,label=kmeansA)\n",
    "ax[cnt].legend(bbox_to_anchor=(1.1, 1.05))\n",
    "ax[cnt].set_ylabel('KMeans \\n detects \"steepness\" changes',fontsize=13)\n",
    "cnt=2\n",
    "ax[cnt].plot(df_input2.index, df_input2[Temperature],linewidth=1,color='black',label=Temperature)\n",
    "ax[cnt].plot(df_input2.index, df_input2[spectral]/spectral_break, linewidth=2,color='dodgerblue', label=spectral)\n",
    "ax[cnt].plot(df_input2.index, df_input2[spectralA]/spectral_break, linewidth=10, color='red') #,label=kmeansA)\n",
    "ax[cnt].legend(bbox_to_anchor=(1.1, 1.05))\n",
    "ax[cnt].set_ylabel('Spectral \\n detects spectrum changes', fontsize=13)\n",
    "cnt=3\n",
    "ax[cnt].plot(df_input2.index, df_input2[Temperature],linewidth=1,color='black',label=Temperature)\n",
    "ax[cnt].plot(df_input2.index, df_input2[fft]/fft_break, linewidth=2,color='darkgreen',label=fft)\n",
    "ax[cnt].plot(df_input2.index, df_input2[fftA]/fft_break, linewidth=10, color='red') #,label=kmeansA)\n",
    "ax[cnt].legend(bbox_to_anchor=(1.1, 1.05))\n",
    "ax[cnt].set_ylabel('FFT \\n detects spectrum changes', fontsize=13)\n",
    "cnt=4\n",
    "ax[cnt].plot(df_input2.index, df_input2[Temperature],linewidth=1,color='black',label=Temperature)\n",
    "ax[cnt].plot(df_input2.index, df_input2[sal]/sal_break, linewidth=2,color='chartreuse', label=sal)\n",
    "ax[cnt].plot(df_input2.index, df_input2[salA]/sal_break, linewidth=10, color='red') #,label=kmeansA)\n",
    "ax[cnt].legend(bbox_to_anchor=(1.1, 1.05))\n",
    "ax[cnt].set_ylabel('Saliency \\n (from computer vision)', fontsize=13)\n",
    "cnt=5\n",
    "ax[cnt].plot(df_input2.index, df_input2[Temperature],linewidth=1,color='black',label=Temperature)\n",
    "#ax[cnt].plot(df_input2.index, df_input2[gen]/gen_break, linewidth=2,color='darkviolet', label=gen)\n",
    "#ax[cnt].plot(df_input2.index, df_input2[genA]/gen_break, linewidth=10, color='red')\n",
    "ax[cnt].legend(bbox_to_anchor=(1.1, 1.05))\n",
    "ax[cnt].set_ylabel('Input data', fontsize=14)\n",
    "\n",
    "for i in range(plots):\n",
    "    ax[i].grid(True, color='white')\n",
    "    ax[i].set_facecolor('lightgrey')\n",
    "\n",
    "#ax.set_ylabel('Temperature-50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we proceed to customer data - BAD CASE\n",
    "\n",
    "# Get stuff in\n",
    "df_inputb_raw = pd.read_csv('./Armstark04714B604101.csv', index_col=False, parse_dates=['RCV_TIMESTAMP_UTC'])\n",
    "df_inputb_raw['entity']=df_inputb_raw['DEVICE_ID']\n",
    "df_inputb_raw['timestamp']=df_inputb_raw['RCV_TIMESTAMP_UTC']\n",
    "\n",
    "# and sort it by timestamp\n",
    "df_inputb_raw = df_inputb_raw.sort_values(by='timestamp')\n",
    "df_inputb_raw = df_inputb_raw.set_index(['entity','timestamp']).dropna()\n",
    "\n",
    "l2norm(df_inputb_raw, 'vibrations', 'VIBRATIONS_XAXIS', 'VIBRATIONS_YAXIS', 'VIBRATIONS_ZAXIS')\n",
    "l2norm(df_inputb_raw, 'rms', 'RMS_X', 'RMS_Y', 'RMS_Z')\n",
    "l2norm(df_inputb_raw, 'accel_speed', 'ACCEL_SPEED')\n",
    "unrollAccel(df_inputb_raw)\n",
    "#l2norm(df_inputb, 'accel_power', 'ACCEL_POWER')\n",
    "\n",
    "df_inputb = df_inputb_raw.filter(listAttr, axis=1)\n",
    "df_inputb.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again run Monitoring's anomaly detector functions\n",
    "\n",
    "salii = SaliencybasedGeneralizedAnomalyScore('vibrations', 12, 'SaliencyVibrationScore')\n",
    "et = salii._build_entity_type(columns = [Column('vibrations',Float())])\n",
    "salii._entity_type = et\n",
    "df_inputb = salii.execute(df=df_inputb)\n",
    "\n",
    "\n",
    "spsii = SpectralAnomalyScore('vibrations', 12, 'SpectralVibrationScore')\n",
    "et = spsii._build_entity_type(columns = [Column('vibrations',Float())])\n",
    "spsii._entity_type = et\n",
    "df_inputb = spsii.execute(df=df_inputb)\n",
    "\n",
    "kmii = KMeansAnomalyScore('vibrations', 12, 'KMeansVibrationScore')\n",
    "et = kmii._build_entity_type(columns = [Column('vibrations',Float())])\n",
    "kmii._entity_type = et\n",
    "df_inputb = kmii.execute(df=df_inputb)\n",
    "\n",
    "fftii = FFTbasedGeneralizedAnomalyScore('vibrations', 12, 'FFTVibrationScore')\n",
    "et = fftii._build_entity_type(columns = [Column('vibrations',Float())])\n",
    "fftii._entity_type = et\n",
    "df_inputb = fftii.execute(df=df_inputb)\n",
    "\n",
    "df_inputb.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EngineLogging.configure_console_logging(logging.INFO)\n",
    "\n",
    "df_inputb2 = df_inputb.loc[['04714B604101']]\n",
    "df_inputb2.reset_index(level=[0], inplace=True)\n",
    "\n",
    "# redefine\n",
    "# setting to make life easier\n",
    "Temperature='vibrations'\n",
    "kmeans='KMeansVibrationScore'\n",
    "fft='FFTVibrationScore'\n",
    "spectral='SpectralVibrationScore'\n",
    "sal='SaliencyVibrationScore'\n",
    "#gen='TemperatureGeneralizedScore'\n",
    "kmeansA='kmeansAnomaly'\n",
    "kmeansB='kmeansAnomalyB'\n",
    "spectralA='spectralAnomaly'\n",
    "fftA='fftAnomaly'\n",
    "salA='salAnomaly'\n",
    "genA='genAnomaly'\n",
    "\n",
    "kmeans_break=1.3\n",
    "spectral_break = 2.8\n",
    "fft_break = 100\n",
    "sal_break = 100\n",
    "gen_break = 30000\n",
    "\n",
    "df_inputb2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_inputb2[spectral].values[df_inputb2[spectral] > 0.001] = 0.001\n",
    "df_inputb2[fft].values[df_inputb2[fft] < -1] = -1\n",
    "df_inputb2[kmeansA] = df_inputb2[kmeans]\n",
    "df_inputb2[kmeansA].values[df_inputb2[kmeansA] < kmeans_break] = np.nan\n",
    "df_inputb2[kmeansA].values[df_inputb2[kmeansA] > kmeans_break] = kmeans_break\n",
    "df_inputb2[kmeansB] = df_inputb2[kmeans]\n",
    "df_inputb2[kmeansB].values[df_inputb2[kmeansB] >= kmeans_break] = 4\n",
    "df_inputb2[kmeansB].values[df_inputb2[kmeansB] < kmeans_break] = 3\n",
    "\n",
    "\n",
    "\n",
    "df_inputb2[fftA] = df_inputb2[fft]\n",
    "df_inputb2[fftA].values[df_inputb2[fftA] < fft_break] = np.nan\n",
    "df_inputb2[fftA].values[df_inputb2[fftA] > fft_break] = fft_break\n",
    "df_inputb2[spectralA] = df_inputb2[spectral]\n",
    "df_inputb2[spectralA].values[df_inputb2[spectralA] < 20] = np.nan\n",
    "df_inputb2[spectralA].values[df_inputb2[spectralA] > 20] = 20\n",
    "df_inputb2[salA] = df_inputb2[sal]\n",
    "df_inputb2[salA].values[df_inputb2[salA] < sal_break] = np.nan\n",
    "df_inputb2[salA].values[df_inputb2[salA] > sal_break] = sal_break\n",
    "#df_input2[genA] = df_input2[gen]\n",
    "#df_input2[genA].values[df_input2[genA] < gen_break] = np.nan\n",
    "#df_input2[genA].values[df_input2[genA] > gen_break] = gen_break\n",
    "\n",
    "plots = 6\n",
    "\n",
    "fig, ax = plt.subplots(plots, 1, figsize=(12,20))\n",
    "cnt=0\n",
    "ax[cnt].plot(df_inputb2.index, df_inputb2[Temperature],linewidth=1,color='black',label=Temperature)\n",
    "ax[cnt].plot(df_inputb2.index, df_inputb2[kmeans], linewidth=2, color='magenta',label=kmeans)\n",
    "ax[cnt].plot(df_inputb2.index, df_inputb2[fft]/fft_break, linewidth=2,color='darkgreen',label=fft)\n",
    "ax[cnt].plot(df_inputb2.index, df_inputb2[spectral]/spectral_break, linewidth=2,color='dodgerblue', label=spectral)\n",
    "ax[cnt].plot(df_inputb2.index, df_inputb2[sal]/sal_break, linewidth=2,color='chartreuse',label=sal)\n",
    "#ax[cnt].plot(df_input2.index, df_input2[gen]/gen_break, linewidth=2,color='darkviolet',label=gen)\n",
    "ax[cnt].legend(bbox_to_anchor=(1.1, 1.05))\n",
    "ax[cnt].set_ylabel('ALL',fontsize=14,weight=\"bold\")\n",
    "cnt=1\n",
    "ax[cnt].plot(df_inputb2.index, df_inputb2[Temperature],linewidth=1,color='black',label=Temperature)\n",
    "ax[cnt].plot(df_inputb2.index, df_inputb2[kmeans], linewidth=2, color='magenta',label=kmeans)\n",
    "ax[cnt].plot(df_inputb2.index, df_inputb2[kmeansA], linewidth=10, color='red') #,label=kmeansA)\n",
    "ax[cnt].legend(bbox_to_anchor=(1.1, 1.05))\n",
    "ax[cnt].set_ylabel('KMeans \\n detects chanages in \"steepness\"',fontsize=13)\n",
    "cnt=2\n",
    "ax[cnt].plot(df_inputb2.index, df_inputb2[Temperature],linewidth=1,color='black',label=Temperature)\n",
    "ax[cnt].plot(df_inputb2.index, df_inputb2[spectral]/20, linewidth=2,color='dodgerblue', label=spectral)\n",
    "ax[cnt].plot(df_inputb2.index, df_inputb2[spectralA]/20, linewidth=10, color='red') #,label=kmeansA)\n",
    "ax[cnt].legend(bbox_to_anchor=(1.1, 1.05))\n",
    "ax[cnt].set_ylabel('Spectral \\n detects spectrum changes', fontsize=13)\n",
    "cnt=3\n",
    "ax[cnt].plot(df_inputb2.index, df_inputb2[Temperature],linewidth=1,color='black',label=Temperature)\n",
    "ax[cnt].plot(df_inputb2.index, df_inputb2[fft]/fft_break, linewidth=2,color='darkgreen',label=fft)\n",
    "ax[cnt].plot(df_inputb2.index, df_inputb2[fftA]/fft_break, linewidth=10, color='red') #,label=kmeansA)\n",
    "ax[cnt].legend(bbox_to_anchor=(1.1, 1.05))\n",
    "ax[cnt].set_ylabel('FFT \\n detects spectrum changes', fontsize=13)\n",
    "cnt=4\n",
    "ax[cnt].plot(df_inputb2.index, df_inputb2[Temperature],linewidth=1,color='black',label=Temperature)\n",
    "ax[cnt].plot(df_inputb2.index, df_inputb2[sal]/sal_break, linewidth=2,color='chartreuse', label=sal)\n",
    "ax[cnt].plot(df_inputb2.index, df_inputb2[salA]/sal_break, linewidth=10, color='red') #,label=kmeansA)\n",
    "ax[cnt].legend(bbox_to_anchor=(1.1, 1.05))\n",
    "ax[cnt].set_ylabel('Saliency \\n (computer vision)', fontsize=13)\n",
    "cnt=5\n",
    "ax[cnt].plot(df_inputb2.index, df_inputb2[Temperature],linewidth=1,color='black',label=Temperature)\n",
    "#ax[cnt].plot(df_inputb2.index, df_inputb2[gen]/gen_break, linewidth=2,color='darkviolet', label=gen)\n",
    "#ax[cnt].plot(df_inputb2.index, df_inputb2[genA]/gen_break, linewidth=10, color='red')\n",
    "ax[cnt].legend()#bbox_to_anchor=(1.1, 1.05))\n",
    "ax[cnt].set_ylabel('Input data', fontsize=13)\n",
    "\n",
    "for i in range(plots):\n",
    "    ax[i].grid(True, color='white')\n",
    "    ax[i].set_facecolor('lightgrey')\n",
    "\n",
    "\n",
    "#ax.set_ylabel('Temperature-50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve FFT\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "# before anomaly \"negatives\"\n",
    "before_anomaly1 = dt.datetime(2020,1,7,0,0,0)  # before anomaly \"negatives\"\n",
    "after_anomaly1 = dt.datetime(2020,1,14,0,0,0)  \n",
    "before_anomaly2 = dt.datetime(2020,1,27,0,0,0) \n",
    "after_anomaly2 = dt.datetime(2020,1,31,0,0,0)\n",
    "\n",
    "df_inputb2.loc[df_inputb2.index < before_anomaly1,'actual'] = 0\n",
    "df_inputb2.loc[(df_inputb2.index > before_anomaly1) &\n",
    "           (df_inputb2.index < after_anomaly1),'actual'] = 1\n",
    "df_inputb2.loc[(df_inputb2.index > after_anomaly1) &\n",
    "           (df_inputb2.index < before_anomaly2),'actual'] = 0\n",
    "df_inputb2.loc[(df_inputb2.index > before_anomaly2) &\n",
    "           (df_inputb2.index < after_anomaly2),'actual'] = 1\n",
    "df_inputb2.loc[(df_inputb2.index > after_anomaly2),'actual'] = 0\n",
    "\n",
    "np_range = np.arange(0, 151, 1)\n",
    "score_list = []\n",
    "fpr_list = []\n",
    "tpr_list = []\n",
    "roc_auc_list = []\n",
    "yyy_test = df_inputb2['actual'].values\n",
    "for ths in np_range:\n",
    "    yyy_score_ = (np.greater(df_inputb2[fft], ths) | np.greater(df_inputb2[sal], ths)).astype(int)\n",
    "    score_list.append(yyy_score_)\n",
    "    fpr_, tpr_, _ = roc_curve(yyy_test, yyy_score_)\n",
    "    fpr_list.append(fpr_)\n",
    "    tpr_list.append(tpr_)\n",
    "    roc_auc_list.append(auc(fpr_,tpr_))\n",
    "\n",
    "    \n",
    "yy_score = np.asarray(score_list)\n",
    "fpr = np.asarray(fpr_list)\n",
    "tpr = np.asarray(tpr_list)\n",
    "roc_auc = np.asarray(roc_auc_list)\n",
    "\n",
    "yyF_score = np.maximum(df_inputb2[fft].values, df_inputb2[sal].values)\n",
    "fprF, tprF, _ = roc_curve(yyy_test, yyF_score/200)\n",
    "roc_aucF = auc(fprF, tprF)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,6))\n",
    "ax.plot(fprF, tprF, color='black', lw=0.5)\n",
    "ax.plot(fpr[20], tpr[20], color='red',lw=1, label='ROC curve 20 (area = %0.2f)' % roc_auc[20])\n",
    "ax.plot(fpr[30], tpr[30], color='turquoise',lw=1, label='ROC curve 30 (area = %0.2f)' % roc_auc[30])\n",
    "ax.plot(fpr[50], tpr[50], color='orange',lw=1, label='ROC curve 50 (area = %0.2f)' % roc_auc[50])\n",
    "ax.plot(fpr[75], tpr[75], color='violet',lw=1, label='ROC curve 75 (area = %0.2f)' % roc_auc[75])\n",
    "ax.plot(fpr[100], tpr[100], color='green',lw=1, label='ROC curve 100 (area = %0.2f)' % roc_auc[100])\n",
    "ax.plot(fpr[150], tpr[150], color='red',lw=1, label='ROC curve 150 (area = %0.2f)' % roc_auc[150])\n",
    "ax.plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate - lower is better, higher means false alerts')\n",
    "plt.ylabel('True Positive Rate - higher is better, we detect more anomalies')\n",
    "plt.title('Receiver operating characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try out supervised methods\n",
    "\n",
    "* Train a stacked LSTM\n",
    "* Run gradient boosting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part of mmfunctions\n",
    "import telemanom\n",
    "from telemanom.telemanom.helpers import Config\n",
    "from telemanom.telemanom.errors import Errors\n",
    "import telemanom.telemanom.helpers as helpers\n",
    "from telemanom.telemanom.channel import Channel\n",
    "from telemanom.telemanom.modeling import Model\n",
    "\n",
    "conf = Config(\"./telemanom/config.yaml\")\n",
    "list_attr=['vibrations','accel_power_0','accel_power_1','accel_power_2','accel_power_3','accel_power_4']\n",
    "#list_attr=['vibrations','accel_power_0']\n",
    "conf.dictionary['l_s'] = 250\n",
    "#conf.dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale higher (*2) to make it a bit harder on the training run\n",
    "\n",
    "tel_input = df_input[list_attr].values\n",
    "tel_input = (tel_input - tel_input.mean())*2\n",
    "tel_inputb = df_inputb[list_attr].values\n",
    "tel_inputb = (tel_inputb - tel_inputb.mean())*2\n",
    "np.save(\"telemanom/data/train/Armstarknew.npy\", tel_input)\n",
    "np.save(\"telemanom/data/test/Armstarknew.npy\", tel_inputb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from \n",
    "device=\"Armstarknew\"\n",
    "chan = Channel(conf, device)\n",
    "helpers.make_dirs(conf.use_id, conf, \"./telemanom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chan.load_data(\"./telemanom\")\n",
    "# chan.train\n",
    "dfA = pd.DataFrame(chan.train)\n",
    "dfA.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chan.train\n",
    "fig, ax = plt.subplots(2, 1, figsize=(20, 7))\n",
    "ax[0].plot((chan.train[:,0]-2)*2, color='blue')\n",
    "ax[0].plot(chan.train[:,1]+0.5, color='green',zorder=1)\n",
    "ax[0].plot(chan.train[:,2]-0.5, color='darkgreen')\n",
    "ax[0].set_title('Train (good) data')\n",
    "ax[1].plot((chan.test[:,0]-2)*2, color='blue')\n",
    "ax[1].plot(chan.test[:,1]+0.5, color='green',zorder=1)\n",
    "ax[1].plot(chan.test[:,2]-0.5, color='darkgreen')\n",
    "ax[1].set_title('Test (bad) data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# producing overlapping windows of length 260 for lookback (250) and prediction (10)\n",
    "chan.shape_data(chan.train, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init the Keras double stacked LSTM model\n",
    "model = Model(conf, conf.use_id, chan, \"./telemanom\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drink a coffee - training takes roughly 7 minutes\n",
    "model.train_new(chan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training parameters\n",
    "\n",
    "```\n",
    "loss_metric: 'mse'    # minimize mean square error\n",
    "optimizer: 'adam'     # sort of adaptive stochastic gradient descent\n",
    "validation_split: 0.2 # 20% of the data is used for validating (val_loss)\n",
    "dropout: 0.3          # ditch 30% of the LSTMs results when minimizing the loss function to avoid overfitting\n",
    "lstm_batch_size: 64   # number of training data batches to evaluate per optimizer run to update the model’s parameters\n",
    "\n",
    "patience: 10          # try at least 10 times to decrease val_loss smaller by ...\n",
    "min_delta: 0.0003     # ... at least min_delta, else stop, so we get at least 'patience' epochs\n",
    "epochs: 35            # no more than 35 passes through the entier training dataset.\n",
    "\n",
    "l_s: 250              # lookback: num previous timesteps provided to model to predict future values\n",
    "n_predictions: 10     # number of steps ahead to predict\n",
    "```\n",
    "\n",
    "This is defined in `telemanom/config.yaml`\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting takes roughly 12 secs\n",
    "model.batch_predict(chan, Path=\"./telemanom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smooth the prediction error and apply exponential weights to it\n",
    "errors = Errors(chan, conf, conf.use_id, \"./telemanom\")\n",
    "\n",
    "#  for each overlapping window establish a threshold so that removing error points above it \n",
    "# maximizes the reduction of mean and standard deviation. Sort of an adaptive z-score \n",
    "errors.process_batches(chan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (errors.E_seq, \" \\n \", errors.anom_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./telemanom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How good are we doing ?\n",
    "\n",
    "model.model.evaluate(chan.X_test, chan.y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.batch_predict(chan, Path=\"./telemanom\", Train=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(20, 7))\n",
    "#ax[0].plot(chan.y_train_hat[:8200] * 10, lw=0.2, color='green')  # to be done\n",
    "ax[0].set_title('Vibration Forecast - good case')\n",
    "ax[1].plot(chan.y_hat, lw=0.5, color='green')\n",
    "ax[1].set_title('Vibration Forecast - bad case')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npic = 1\n",
    "fig, ax = plt.subplots(npic+1, 1, figsize=(20, (npic+1) * 5))\n",
    "ax[npic-1].set_title('Anomaly detection - forecasting vibration based on acceleration')\n",
    "ax[npic-1].plot(chan.y_test[:,0], lw=1, color='blue', label='vibration')\n",
    "\n",
    "#ax.scatter(x_axis, temp_sal_high, lw=8, color='red')\n",
    "for asc in errors.anom_scores:\n",
    "    x_axis = np.arange(asc['start_idx'],asc['end_idx'],1)\n",
    "    y_axis = np.zeros(asc['end_idx'] - asc['start_idx'])\n",
    "    ax[npic-1].grid(True, color='white')\n",
    "    ax[npic-1].set_facecolor('lightgrey')\n",
    "    ax[npic-1].scatter(x_axis,y_axis+1.5, lw=5, color='red', zorder=10)\n",
    "ax[npic-1].grid(True, color='white')\n",
    "ax[npic-1].set_facecolor('lightgrey')\n",
    "ax[npic-1].plot(abs(chan.y_hat - chan.y_test[:,0]) + 3, lw=3, color='green', label='deviation')\n",
    "ax[npic-1].plot(chan.y_hat - 0.3, lw=2, color='darkgreen',label='prediction')\n",
    "ax[npic-1].legend()\n",
    "    \n",
    "ax[npic].set_xlabel('Epoch')\n",
    "ax[npic].set_ylabel('Loss')\n",
    "ax[npic].set_title('Model training history')\n",
    "ax[npic].plot(model.history.history['loss'])\n",
    "ax[npic].plot(model.history.history['val_loss'],color='green')\n",
    "ax[npic].grid(True, color='white')\n",
    "ax[npic].set_facecolor('gainsboro')\n",
    "ax[npic].legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "#ax[1].plot(chan.test[:,0], lw=1, color='blue')\n",
    "#ax[1].set_xlabel('Date')\n",
    "#ax[1].set_ylabel('Compare with raw training data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now run gradient boosting - using lightGBM\n",
    "\n",
    "X_train = df_input[['accel_speed','accel_power_0','accel_power_1','accel_power_2',\n",
    "                    'accel_power_3','accel_power_4']].to_numpy()\n",
    "y_train = df_input['vibrations'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm\n",
    "gbr = lightgbm.LGBMRegressor(n_estimators=4000, learning_rate=0.000001, num_leaves=40,\n",
    "                           max_depth=20, random_state=42, loss='huber').fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred_good = gbr.predict(X_train)\n",
    "rmse = metrics.mean_squared_error(y_train, pred_good)\n",
    "gbscoreg = np.abs(pred_good - y_train)\n",
    "print (rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bad = df_inputb[['accel_speed','accel_power_0','accel_power_1','accel_power_2',\n",
    "                   'accel_power_3','accel_power_4']].to_numpy()\n",
    "y_bad = df_inputb['vibrations'].to_numpy()\n",
    "pred_bad = gbr.predict(X_bad) \n",
    "rmseb = metrics.mean_squared_error(y_bad, pred_bad)\n",
    "gbscore = np.abs(pred_bad - y_bad)\n",
    "print (rmseb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "separator = 0.2\n",
    "anomalygb = gbscore.copy() #(gbscore > separator) # * (separator + 0.1)\n",
    "anomalygb[anomalygb <= separator] = 0\n",
    "anomalygb[anomalygb > separator] = separator/2\n",
    "anomalygb[anomalygb == 0] = np.nan\n",
    "anomalygg = gbscoreg.copy()\n",
    "anomalygg[anomalygg <= separator] = 0\n",
    "anomalygg[anomalygg > separator] = separator/2\n",
    "anomalygg[anomalygg == 0] = np.nan\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, figsize=(12,14)) \n",
    "ax1.plot(y_bad, color='blue')\n",
    "ax1.set_title('Bad Case - Input vibrations', fontsize=10)\n",
    "ax1.set_ylabel('vibration')\n",
    "ax2.plot(gbscore, color='green')\n",
    "ax2.plot(anomalygb, color='red', lw=12, zorder=10)\n",
    "ax2.set_ylabel('||actual-pred||')\n",
    "ax2.set_title('Bad Case - deviating predictions', fontsize=10)\n",
    "ax3.plot(y_train, color='blue')\n",
    "ax3.set_ylabel('vibration')\n",
    "ax3.set_title('Good Case - Input vibrations', fontsize=10)\n",
    "ax4.plot(gbscoreg, color='green')\n",
    "ax4.plot(anomalygg, color='red', lw=12, zorder=10)\n",
    "ax4.set_ylabel('||actual-pred||')\n",
    "ax4.set_title('Good Case - no anomalous deviation from prediction', fontsize=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve FFT\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "# before anomaly \"negatives\"\n",
    "before_anomaly1 = dt.datetime(2020,1,7,0,0,0)  # before anomaly \"negatives\"\n",
    "after_anomaly1 = dt.datetime(2020,1,14,0,0,0)  \n",
    "before_anomaly2 = dt.datetime(2020,1,27,0,0,0) \n",
    "after_anomaly2 = dt.datetime(2020,1,31,0,0,0)\n",
    "\n",
    "df_inputb2.loc[df_inputb2.index < before_anomaly1,'actual'] = 0\n",
    "df_inputb2.loc[(df_inputb2.index > before_anomaly1) &\n",
    "           (df_inputb2.index < after_anomaly1),'actual'] = 1\n",
    "df_inputb2.loc[(df_inputb2.index > after_anomaly1) &\n",
    "           (df_inputb2.index < before_anomaly2),'actual'] = 0\n",
    "df_inputb2.loc[(df_inputb2.index > before_anomaly2) &\n",
    "           (df_inputb2.index < after_anomaly2),'actual'] = 1\n",
    "df_inputb2.loc[(df_inputb2.index > after_anomaly2),'actual'] = 0\n",
    "\n",
    "yyy_test = df_inputb2['actual'].values\n",
    "fprFg, tprFg, _ = roc_curve(yyy_test, gbscore)\n",
    "roc_aucFg = auc(fprFg, tprFg)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7,5))\n",
    "ax.plot(fprF, tprF, color='red', lw=2, label='ROC curve (area = %0.2f)' % roc_aucF)\n",
    "ax.plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate\\nlower is better, higher means false alerts')\n",
    "plt.ylabel('True Positive Rate\\nhigher is better, we detect more anomalies')\n",
    "plt.title('ROC - gradient boosting', fontsize=14)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "Gradient boosting appears to do much better\n",
    "\n",
    "- Much shorter training time compared to the NASA model\n",
    "- Prediction\n",
    "\n",
    "To be investigated further\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
